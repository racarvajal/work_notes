{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to gather data from $z > 5.5$ QSOs.\n",
    "\n",
    "We want to obtain data from several surveys and catalogs in order to  \n",
    "manipulate them and try to obtain meaningful correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the packages to be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the first line working, you need  \n",
    "to run the following lines:\n",
    "\n",
    "```bash\n",
    " conda install nodejs\n",
    " pip install ipympl\n",
    " pip install --upgrade jupyterlab\n",
    " jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    " jupyter labextension install jupyter-matplotlib\n",
    " jupyter nbextension enable --py widgetsnbextension\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Static plots\n",
    "#%matplotlib ipympl\n",
    "# Interactive plots\n",
    "import numpy as np\n",
    "# import matplotlib.cm as cm\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.colors as mcolors\n",
    "# import matplotlib.patheffects as mpe\n",
    "# import matplotlib.patheffects as path_effects\n",
    "# from matplotlib.ticker import FormatStrFormatter\n",
    "# from matplotlib.patches import Polygon\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astropy.table import Column\n",
    "from astropy.table import MaskedColumn\n",
    "from astropy.table import hstack\n",
    "from astropy.table import vstack\n",
    "from astropy.wcs import WCS\n",
    "from astropy import units as u\n",
    "# from astropy.visualization import hist\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astroquery.simbad import Simbad\n",
    "from astroquery.ned import Ned\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One function, to derive luminosity distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def luminosity_distance(z_i, H0=70., WM=0.3, WV=0.7):\n",
    "    z_i   = np.array([z_i], dtype='float64').flatten()\n",
    "    c     = 299792.458 # velocity of light in km/sec\n",
    "    h     = H0 / 100.\n",
    "    WR    = 4.165E-5 / (h * h)   # includes 3 massless neutrino species, T0 = 2.72528\n",
    "    WK    = 1 - WM - WR - WV\n",
    "    azs   = 1.0 / (1 + z_i)\n",
    "    DTT   = 0.0\n",
    "    DCMR  = 0.0\n",
    "    # do integral over a=1/(1+z) from az to 1 in n steps, midpoint rule\n",
    "    n     = 1000  # number of points in integrals\n",
    "    DL_Mpcs = np.zeros_like(z_i)\n",
    "    for count, az in enumerate(azs):\n",
    "        a     = az + (1 - az) * (np.arange(0, n) + 0.5) / n\n",
    "        adot  = np.sqrt(WK + (WM / a) + (WR / (a * a)) + (WV * a * a))\n",
    "        for i in range(n):\n",
    "            # a    = az + (1 - az) * (i + 0.5) / n\n",
    "            # adot = math.sqrt(WK + (WM / a) + (WR / (a * a)) + (WV * a * a))\n",
    "            DTT  = DTT + 1. / adot[i]\n",
    "            DCMR = DCMR + 1. / (a[i] * adot[i])\n",
    "        DTT   = (1. - az) * DTT / n\n",
    "        DCMR  = (1. - az) * DCMR / n\n",
    "        # tangential comoving distance\n",
    "        ratio = 1.00\n",
    "        x     = np.sqrt(abs(WK)) * DCMR\n",
    "        if x > 0.1:\n",
    "            if WK > 0:\n",
    "                ratio =  0.5 * (np.exp(x) - np.exp(-x)) / x \n",
    "            else:\n",
    "                ratio = np.sin(x) / x\n",
    "        else:\n",
    "            y = x * x\n",
    "        if WK < 0: y = -y\n",
    "        ratio  = 1. + y / 6. + y * y / 120.\n",
    "        DCMT   = ratio * DCMR\n",
    "        DA     = az * DCMT\n",
    "        DL     = DA / (az * az)\n",
    "        DL_Mpc = (c / H0) * DL\n",
    "        DL_Mpcs[count] = DL_Mpc\n",
    "    return DL_Mpcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the spectral index $\\alpha$ from different sources  \n",
    "to be used in the luminosity calculations (K-correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_first = 0.5  # From FIRST data (Bornancini+2010)\n",
    "alpha_RG    = 1.0  # For radio galaxies (Verkhodanov & Khabibullina, 2010)\n",
    "alpha_alex  = 0.8  # Star-forming galaxies (Alexander+2003)\n",
    "alpha_smol  = 0.7  # Mean value from VLA-COSMOS 3GHz sample (Smolčić et al. 2017)\n",
    "alpha_butl  = 0.75  # From Butler et al., 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose one of the spectral indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_used  = alpha_butl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step, reading our data.  \n",
    "Most of the data files have been created using Topcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine  = getpass.getuser()\n",
    "# cat_path = '/home/' + machine + '/Documentos/Data/'\n",
    "cat_path = ''  # relative path to the same directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from FIRST+MILLIQUAS catalogs cross-matched.  \n",
    "\n",
    "**MILLIQUAS + FIRST (SDSS)**   \n",
    "\n",
    "Redshift values have been retrieved from the column `pipeline_redshift` in SDSS DR12  \n",
    "The procedure to obtain these values is explained in **Bolton+2012**  \n",
    "\n",
    "We also select sources with have explicitely data in both SDSS Quasar Catalog and  \n",
    "in the FIRST survey (`first_match_flag = 1`).  \n",
    "\n",
    "In order to get only the best redshift values, we select sources with  \n",
    "`pipeline_redshift_flag = 0`.\n",
    "\n",
    "Thus, we can use 9161 objects from the catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu_list = fits.open(cat_path + 'tables_matches_milli_sdss_apr.fits');\n",
    "\n",
    "# wise_milli  = Table(hdu_list[1].data);\n",
    "sdss_milli  = Table(hdu_list[1].data);\n",
    "# match_table = Table(hdu_list[3].data);  # Three tables cross-matched\n",
    "hdu_list.close();\n",
    "\n",
    "L_14GHz_filter = np.array((sdss_milli['L_14GHz'] > 0.0) * (sdss_milli['first_offset'] < 1.0)) ;  # sdss + milliquasar\n",
    "\n",
    "#np.sum(L_14GHz_filter)\n",
    "#sdss_milli['name', 'redshift', 'redshift_err', 'first_offset', 'spec_index'][L_14GHz_filter * np.array(sdss_milli['redshift'] > 5.5)].show_in_browser(jsviewer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want, also, to add $z > 6$ QSOs from the list in  \n",
    "Table 3 in the review of **Inayoshi, Visbal, and Haiman, 2020**.  \n",
    "Six of them have $z > 7$\n",
    "\n",
    "Not all of them have $1.4$ GHz measurements. Others have  \n",
    "measurements in different frequencies which can be translated  \n",
    "into the desired frequency using, for instance, the relation  \n",
    "from **Butler et al., 2018**:\n",
    "\n",
    "$$S_{a} = S_{b} \\times (\\frac{\\nu_{b}}{\\nu_{a}})^{\\alpha}$$  \n",
    "\n",
    "We load the data from these sources. Fluxes from different frequencies than $1.4$ GHz are translated to the needed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_z_zs        = np.char.replace(np.loadtxt(cat_path + 'high_z_qso_props.csv', usecols=[3],  dtype='str', delimiter=';'), ',', '.').astype(np.float)\n",
    "high_z_zs_e      = np.char.replace(np.loadtxt(cat_path + 'high_z_qso_props.csv', usecols=[4],  dtype='str', delimiter=';'), ',', '.').astype(np.float)\n",
    "high_z_14GHz     = np.char.replace(np.loadtxt(cat_path + 'high_z_qso_props.csv', usecols=[6],  dtype='str', delimiter=';'), ',', '.').astype(np.float)\n",
    "high_z_14GHz_e   = np.char.replace(np.loadtxt(cat_path + 'high_z_qso_props.csv', usecols=[7],  dtype='str', delimiter=';'), ',', '.').astype(np.float)\n",
    "high_z_3GHz      = np.char.replace(np.loadtxt(cat_path + 'high_z_qso_props.csv', usecols=[8],  dtype='str', delimiter=';'), ',', '.').astype(np.float)\n",
    "high_z_3GHz_e    = np.char.replace(np.loadtxt(cat_path + 'high_z_qso_props.csv', usecols=[9],  dtype='str', delimiter=';'), ',', '.').astype(np.float)\n",
    "high_z_15GHz     = np.char.replace(np.loadtxt(cat_path + 'high_z_qso_props.csv', usecols=[10], dtype='str', delimiter=';'), ',', '.').astype(np.float)\n",
    "high_z_15GHz_e   = np.char.replace(np.loadtxt(cat_path + 'high_z_qso_props.csv', usecols=[11], dtype='str', delimiter=';'), ',', '.').astype(np.float)\n",
    "high_z_250GHz    = np.char.replace(np.loadtxt(cat_path + 'high_z_qso_props.csv', usecols=[12], dtype='str', delimiter=';'), ',', '.').astype(np.float)\n",
    "high_z_250GHz_e  = np.char.replace(np.loadtxt(cat_path + 'high_z_qso_props.csv', usecols=[13], dtype='str', delimiter=';'), ',', '.').astype(np.float)\n",
    "high_z_mass_1450 = np.char.replace(np.loadtxt(cat_path + 'high_z_qso_props.csv', usecols=[14], dtype='str', delimiter=';'), ',', '.').astype(np.float)\n",
    "high_z_names     = np.loadtxt('high_z_qso_props.csv', usecols=[0], dtype='str', delimiter=';')\n",
    "high_z_lum_d     = luminosity_distance(high_z_zs) * 3.086e22  # in m\n",
    "high_z_up_lim    = np.array([val == '<' for val in np.loadtxt('high_z_qso_props.csv', usecols=[5], dtype='str', delimiter=';')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accumulate values into one array except 250GHz data.  \n",
    "Millimetre luminosities will be used separately since we cannot be completely  \n",
    "sure that they represent, fully, non-thermal emission (from AGN) and not dust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_z_14   = high_z_14GHz + high_z_3GHz + high_z_15GHz\n",
    "high_z_14_e = high_z_14GHz_e + high_z_3GHz_e + high_z_15GHz_e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate luminosities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate luminosities (in W/Hz) for different datasets  \n",
    "using the expression\n",
    "\n",
    "$$L_{1.4\\mathrm{GHz}} = 4 \\pi \\mathrm{d}^{2}_{L} f_{1.4\\mathrm{GHz}} (1 + z)^{\\alpha - 1}$$\n",
    "\n",
    "which comes from Alexander et al. 2003\n",
    "\n",
    "We can also obtain that luminosity from the flux in $3$ GHz as\n",
    "\n",
    "$$L_{1.4\\mathrm{GHz}} = 4 \\pi \\mathrm{d}^{2}_{L} {(\\frac{3}{1.4})}^{\\alpha} f_{3\\mathrm{GHz}} (1 + z)^{\\alpha - 1}$$\n",
    "\n",
    "This expression comes from Delhaize et al. 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_21cm      = 4 * np.pi * (sdss_milli['D_lum'][L_14GHz_filter])**2 * sdss_milli['flux_20_cm'][L_14GHz_filter] * 1e-3 * 1e-26 * (1 + sdss_milli['redshift'][L_14GHz_filter])**(alpha_used - 1)\n",
    "L_21cm_e    = np.abs(L_21cm) / sdss_milli['snr_20_cm'][L_14GHz_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_z_lum_14    = 4 * np.pi * high_z_lum_d**2 * high_z_14GHz  * 1e-6 * 1e-26 * (1 + high_z_zs)**(alpha_used - 1)\n",
    "high_z_lum_3     = 4 * np.pi * high_z_lum_d**2 * high_z_3GHz   * 1e-6 * 1e-26 * (1 + high_z_zs)**(alpha_used - 1) * (3/1.4)**alpha_used\n",
    "high_z_lum_15    = 4 * np.pi * high_z_lum_d**2 * high_z_15GHz  * 1e-6 * 1e-26 * (1 + high_z_zs)**(alpha_used - 1) * (1.5/1.4)**alpha_used\n",
    "high_z_lum_250   = 4 * np.pi * high_z_lum_d**2 * high_z_250GHz * 1e-6 * 1e-26 * (1 + high_z_zs)**(alpha_used - 1) * (250/1.4)**(alpha_used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mix all luminosities (different bands) to obtain single value (adding zeroes).  \n",
    "Millimetre luminosities will be used separately since we cannot be completely  \n",
    "sure that they represent, fully, non-thermal emission (from AGN) and not dust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_z_lum_14GHz   = high_z_lum_14 + high_z_lum_3 + high_z_lum_15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also determine error values for these luminosities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_z_lum_14GHz_e  = np.zeros_like(high_z_lum_14GHz)\n",
    "high_z_lum_250GHz_e = np.zeros_like(high_z_lum_250)\n",
    "for counter, element in enumerate(high_z_lum_14GHz):\n",
    "    if element == 0: continue\n",
    "    high_z_lum_14GHz_e[counter] = np.abs(element) * high_z_14_e[counter] / high_z_14[counter]\n",
    "for counter, element in enumerate(high_z_lum_250):\n",
    "    if element == 0: continue\n",
    "    high_z_lum_250GHz_e[counter] = np.abs(element) * high_z_250GHz_e[counter] / high_z_250GHz[counter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a filter to plot, when needed, only the sources which  \n",
    "have mm data but not radio observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_250GHz = np.array((high_z_lum_250 > 0) * (high_z_lum_14GHz == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the points we are interested in. Our sample from **Inayoshi et al., 2020** and the  \n",
    "sources from **SDSS+FIRST** with $z>5.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option to display the data is, instead of showing redshift in the  \n",
    "horizontal axis, have the mass of the observed objects.\n",
    "\n",
    "**Inayoshi et al., 2020** use the rest-frame UV magnitude $\\mathrm{M}_{1450}$  \n",
    "to calculate the mass as:\n",
    "\n",
    "$$M = 10^{[-(\\mathrm{M}_{1450} + 3.459) / 2.5]} [\\mathrm{M}_{\\odot}]$$\n",
    "\n",
    "which yields, on average, the published virial mass estimates for those available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_sdss_L          = L_21cm[np.array(sdss_milli['redshift'][L_14GHz_filter] > 5.5)]\n",
    "upper_sdss_L_e        = L_21cm_e[np.array(sdss_milli['redshift'][L_14GHz_filter] > 5.5)]\n",
    "upper_sdss_u_lim      = np.zeros_like(upper_sdss_L, dtype=np.bool)\n",
    "upper_sdss            = sdss_milli[np.array(sdss_milli['redshift'] > 5.5) * L_14GHz_filter]\n",
    "upper_sdss_z          = upper_sdss['redshift']\n",
    "upper_sdss_z_e        = upper_sdss['redshift_err']\n",
    "upper_sdss_f_20cm     = upper_sdss['flux_20_cm']  # mJy\n",
    "upper_sdss_f_20cm_e   = upper_sdss['flux_20_cm'] / upper_sdss['snr_20_cm']  # mJy\n",
    "upper_sdss_f_250GHz   = np.zeros_like(upper_sdss_L)\n",
    "upper_sdss_f_250GHz_e = np.zeros_like(upper_sdss_L)\n",
    "upper_sdss_L_250GHz   = np.zeros_like(upper_sdss_L)\n",
    "upper_sdss_L_250GHz_e = np.zeros_like(upper_sdss_L)\n",
    "upper_sdss_mass_1450  = np.zeros_like(upper_sdss_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_sample_L         = np.append(upper_sdss_L, high_z_lum_14GHz[np.array(high_z_lum_14GHz>0)])  # W/Hz\n",
    "large_sample_L_e       = np.append(upper_sdss_L_e, high_z_lum_14GHz_e[np.array(high_z_lum_14GHz>0)])  # W/Hz\n",
    "large_sample_u_lim     = np.append(upper_sdss_u_lim, high_z_up_lim[np.array(high_z_lum_14GHz>0)])\n",
    "large_sample_L_250     = np.append(upper_sdss_L_250GHz, high_z_lum_250[np.array(high_z_lum_14GHz>0)])\n",
    "large_sample_L_250_e   = np.append(upper_sdss_L_250GHz_e, high_z_lum_250GHz_e[np.array(high_z_lum_14GHz>0)])\n",
    "large_sample_f20cm     = np.append(upper_sdss_f_20cm, high_z_14[np.array(high_z_lum_14GHz>0)] * 1e-3)  # mJy\n",
    "large_sample_f20cm_e   = np.append(upper_sdss_f_20cm_e, high_z_14_e[np.array(high_z_lum_14GHz>0)] * 1e-3)  # mJy\n",
    "large_sample_f250GHz   = np.append(upper_sdss_f_250GHz, high_z_250GHz[np.array(high_z_lum_14GHz>0)] * 1e-3)  # mJy\n",
    "large_sample_f250GHz_e = np.append(upper_sdss_f_250GHz_e, high_z_250GHz_e[np.array(high_z_lum_14GHz>0)] * 1e-3)  # mJy\n",
    "large_sample_z         = np.append(upper_sdss_z, high_z_zs[np.array(high_z_lum_14GHz>0)])\n",
    "large_sample_z_e       = np.append(upper_sdss_z_e, high_z_zs_e[np.array(high_z_lum_14GHz>0)])\n",
    "large_sample_mass_1450 = np.append(upper_sdss_mass_1450, high_z_mass_1450[np.array(high_z_lum_14GHz>0)])  # M_sun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we also want to obtain more properties from the selected  \n",
    "sources (**Inayoshi et al., 2020** + **SDSS+FIRST**). We will use `astroquery` to  \n",
    "obtain information from `simbad`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we obtain the names of our sources to query them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_sample_names = np.append(upper_sdss['name'], high_z_names[np.array(high_z_lum_14GHz>0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can query the database to obtain the desired data.  In this point,  \n",
    "we also add more columns to be queried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "customSimbad   = Simbad()\n",
    "initial_fields = customSimbad.get_votable_fields()\n",
    "\n",
    "if 'coordinates' in initial_fields:\n",
    "    customSimbad.remove_votable_fields('coordinates')\n",
    "    customSimbad.add_votable_fields('ra(d)', 'dec(d)')\n",
    "if 'z_value' not in initial_fields:\n",
    "    customSimbad.add_votable_fields('z_value')\n",
    "for band in ['B','V','R','I','J','K']:\n",
    "    if f'fluxdata({band})' not in initial_fields:\n",
    "        customSimbad.add_votable_fields(f'flux({band})', f'flux_error({band})')\n",
    "\n",
    "\n",
    "result_table = customSimbad.query_objects(large_sample_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point, we merge the data from the query to `simbad` with the  \n",
    "values from this notebook (**Inayoshi et al., 2020** and **SDSS+FIRST**).  \n",
    "In order to do this, we convert the data into `astropy` columns, and then  \n",
    "into `astropy` tables. They will be ready to be exported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_z_own        = MaskedColumn(large_sample_z, name='Z_OWN', unit='', description='Redshift from Inayoshi+2020 or SDSS+FIRST', fill_value=np.nan)\n",
    "column_z_own_err    = MaskedColumn(large_sample_z_e, name='Z_OWN_ERR', unit='', description='Redshift error from Inayoshi+2020 or SDSS+FIRST', fill_value=np.nan)\n",
    "column_L_14GHz      = MaskedColumn(large_sample_L, name='L_20CM', unit='W/Hz', description='Luminosity in 1.4 GHz', fill_value=np.nan)\n",
    "column_L_14GHz_err  = MaskedColumn(large_sample_L_e, name='L_20CM_ERR', unit='W/Hz', description='Luminosity error in 1.4 GHz', fill_value=np.nan)\n",
    "column_L_14GHz_up   = MaskedColumn(large_sample_u_lim, name='L_20CM_UP_LIM', dtype='bool', description='True if L_20CM is upper limit')\n",
    "column_L_250GHz     = MaskedColumn(large_sample_L_250, name='L_250GHZ', unit='W/Hz', description='Luminosity in 250 GHz', fill_value=np.nan)\n",
    "column_L_250GHz_err = MaskedColumn(large_sample_L_250_e, name='L_250GHZ_ERR', unit='W/Hz', description='Luminosity error in 250 GHz', fill_value=np.nan)\n",
    "column_f_20cm       = MaskedColumn(large_sample_f20cm, name='F_20CM', unit='mJy', description='Flux in 20 cm', fill_value=np.nan)\n",
    "column_f_20cm_err   = MaskedColumn(large_sample_f20cm_e, name='F_20CM_ERR', unit='mJy', description='Flux error in 20 cm', fill_value=np.nan)\n",
    "column_f_250GHz     = MaskedColumn(large_sample_f250GHz, name='F_250GHZ', unit='mJy', description='Flux in 250 GHz', fill_value=np.nan)\n",
    "column_f_250GHz_err = MaskedColumn(large_sample_f250GHz_e, name='F_250GHZ_ERR', unit='mJy', description='Flux error in 250 GHz', fill_value=np.nan)\n",
    "column_mass_1450    = MaskedColumn(large_sample_mass_1450, name='MASS_1450', unit='Msun', description='Mass from mag_1450 (UV)', fill_value=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table.add_columns([column_z_own, column_z_own_err, column_L_14GHz, column_L_14GHz_err, column_L_14GHz_up, column_L_250GHz, column_L_250GHz_err, column_f_20cm, column_f_20cm_err, column_f_250GHz, column_f_250GHz_err, column_mass_1450])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_id = result_table['MAIN_ID'].astype('str')\n",
    "result_table.replace_column('MAIN_ID', str_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_table = result_table.filled(fill_value=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write the table into a file. It can be `.fits`, `.votable`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy_table.write('high_z_qsos.ecsv', format='ascii.ecsv', overwrite=True, serialize_method='data_mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the objects of the table in other catalogs and services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from astroquery.heasarc import Heasarc\n",
    "#Heasarc.query_mission_cols(mission='radio')\n",
    "#tabb = Heasarc.query(large_sample_names, mission='radio', timeout=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "customNed        = Ned()\n",
    "fields_to_remove = ['No.', 'Photometry Measurement', 'Uncertainty', 'Units', 'Frequency', 'Significance', 'Published frequency', 'Frequency Mode', 'Coordinates Targeted', 'Spatial Mode', 'Qualifiers', 'Comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_counter = 0\n",
    "res_tab       = {}\n",
    "for name in large_sample_names:\n",
    "    try:\n",
    "        res_tab[name] = customNed.get_table(name)\n",
    "        res_tab[name].remove_columns(fields_to_remove)\n",
    "    except:\n",
    "        res_tab[name] = Table()\n",
    "        empty_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table_copy     = result_table.copy()\n",
    "for index, source_name in enumerate(large_sample_names):\n",
    "    band_names_str    = []\n",
    "    column_names_str  = []\n",
    "    measure_names     = res_tab[source_name].colnames[1:]\n",
    "    init_table        = Table([[str(source_name)]], names=['MAIN_ID'])\n",
    "    for row in res_tab[source_name]:\n",
    "        band_name_str = str(row['Observed Passband'].decode('utf-8'))\n",
    "        if str(band_name_str) not in band_names_str:\n",
    "            band_names_str.append(str(band_name_str))\n",
    "            for measurement in measure_names:\n",
    "                new_column_name = band_name_str.replace(' ', '_') + '_' + str(measurement).replace(' ', '_')\n",
    "                if new_column_name not in column_names_str:\n",
    "                    column_names_str.append(new_column_name)\n",
    "                    #print(column_names_str[-2::])\n",
    "                    temp_column = MaskedColumn(row[measurement], name=new_column_name)\n",
    "                    #print(temp_column)\n",
    "                    init_table.add_column(temp_column)\n",
    "    init_table.remove_column('MAIN_ID')\n",
    "    if index == 0:\n",
    "        init_table_large  = init_table.copy()\n",
    "    if index != 0:\n",
    "        init_table_large  = vstack([init_table_large, init_table])\n",
    "    #print(index)\n",
    "result_table_copy = hstack([result_table_copy, init_table_large])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_table_copy['MAIN_ID', '1.4_GHz_(VLA)_Flux_Density', '1.4GHz_Flux_Density'].show_in_browser(jsviewer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Table length=52>\n",
      "           name             dtype          mean                 std            min    max   n_bad\n",
      "-------------------------- ------- -------------------- -------------------- ------- ------ -----\n",
      "1.4_GHz_(VLA)_Flux_Density float64 0.006062857142857142 0.006415414638165785 2.6e-05 0.0186    45\n",
      "       1.4GHz_Flux_Density float64  0.01780142857142857  0.02275488169198703 0.00127 0.0715    45\n"
     ]
    }
   ],
   "source": [
    "result_table_copy['1.4_GHz_(VLA)_Flux_Density', '1.4GHz_Flux_Density'].info(['attributes', 'stats'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for name in large_sample_names:\n",
    "#    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "52 - empty_counter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
