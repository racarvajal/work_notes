{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to gather data from $z > 5.5$ QSOs.\n",
    "\n",
    "We want to obtain data from several surveys and catalogs in order to  \n",
    "manipulate them and try to obtain meaningful correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the packages to be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the first line working, you need  \n",
    "to run the following lines:\n",
    "\n",
    "```bash\n",
    " conda install nodejs\n",
    " pip install ipympl\n",
    " pip install --upgrade jupyterlab\n",
    " jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    " jupyter labextension install jupyter-matplotlib\n",
    " jupyter nbextension enable --py widgetsnbextension\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Static plots\n",
    "#%matplotlib ipympl\n",
    "# Interactive plots\n",
    "import numpy as np\n",
    "# import matplotlib.cm as cm\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.colors as mcolors\n",
    "# import matplotlib.patheffects as mpe\n",
    "# import matplotlib.patheffects as path_effects\n",
    "# from matplotlib.ticker import FormatStrFormatter\n",
    "# from matplotlib.patches import Polygon\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astropy.table import Column\n",
    "from astropy.table import MaskedColumn\n",
    "from astropy.table import hstack\n",
    "from astropy.table import vstack\n",
    "from astropy.table import join\n",
    "from astropy.wcs import WCS\n",
    "from astropy import units as u\n",
    "# from astropy.visualization import hist\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astroquery.simbad import Simbad\n",
    "from astroquery.ned import Ned\n",
    "import getpass\n",
    "import progressbar\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One function, to derive luminosity distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def luminosity_distance(z_i, H0=70., WM=0.3, WV=0.7):\n",
    "    z_i   = np.array([z_i], dtype='float64').flatten()\n",
    "    c     = 299792.458 # velocity of light in km/sec\n",
    "    h     = H0 / 100.\n",
    "    WR    = 4.165E-5 / (h * h)   # includes 3 massless neutrino species, T0 = 2.72528\n",
    "    WK    = 1 - WM - WR - WV\n",
    "    azs   = 1.0 / (1 + z_i)\n",
    "    DTT   = 0.0\n",
    "    DCMR  = 0.0\n",
    "    # do integral over a=1/(1+z) from az to 1 in n steps, midpoint rule\n",
    "    n     = 1000  # number of points in integrals\n",
    "    DL_Mpcs = np.zeros_like(z_i)\n",
    "    for count, az in enumerate(azs):\n",
    "        a     = az + (1 - az) * (np.arange(0, n) + 0.5) / n\n",
    "        adot  = np.sqrt(WK + (WM / a) + (WR / (a * a)) + (WV * a * a))\n",
    "        for i in range(n):\n",
    "            # a    = az + (1 - az) * (i + 0.5) / n\n",
    "            # adot = math.sqrt(WK + (WM / a) + (WR / (a * a)) + (WV * a * a))\n",
    "            DTT  = DTT + 1. / adot[i]\n",
    "            DCMR = DCMR + 1. / (a[i] * adot[i])\n",
    "        DTT   = (1. - az) * DTT / n\n",
    "        DCMR  = (1. - az) * DCMR / n\n",
    "        # tangential comoving distance\n",
    "        ratio = 1.00\n",
    "        x     = np.sqrt(abs(WK)) * DCMR\n",
    "        if x > 0.1:\n",
    "            if WK > 0:\n",
    "                ratio =  0.5 * (np.exp(x) - np.exp(-x)) / x \n",
    "            else:\n",
    "                ratio = np.sin(x) / x\n",
    "        else:\n",
    "            y = x * x\n",
    "        if WK < 0: y = -y\n",
    "        ratio  = 1. + y / 6. + y * y / 120.\n",
    "        DCMT   = ratio * DCMR\n",
    "        DA     = az * DCMT\n",
    "        DL     = DA / (az * az)\n",
    "        DL_Mpc = (c / H0) * DL\n",
    "        DL_Mpcs[count] = DL_Mpc\n",
    "    return DL_Mpcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the spectral index $\\alpha$ from different sources  \n",
    "to be used in the luminosity calculations (K-correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_first = 0.5  # From FIRST data (Bornancini+2010)\n",
    "alpha_RG    = 1.0  # For radio galaxies (Verkhodanov & Khabibullina, 2010)\n",
    "alpha_alex  = 0.8  # Star-forming galaxies (Alexander+2003)\n",
    "alpha_smol  = 0.7  # Mean value from VLA-COSMOS 3GHz sample (Smolčić et al. 2017)\n",
    "alpha_butl  = 0.75  # From Butler et al., 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose one of the spectral indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_used  = alpha_butl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step, reading our data.  \n",
    "Most of the data files have been created using Topcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine  = getpass.getuser()\n",
    "# cat_path = '/home/' + machine + '/Documentos/Data/'\n",
    "cat_path = ''  # relative path to the same directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from FIRST+MILLIQUAS catalogs cross-matched.  \n",
    "\n",
    "**MILLIQUAS + FIRST (SDSS)**   \n",
    "\n",
    "Redshift values have been retrieved from the column `pipeline_redshift` in SDSS DR12  \n",
    "The procedure to obtain these values is explained in **Bolton+2012**  \n",
    "\n",
    "We also select sources with have explicitely data in both SDSS Quasar Catalog and  \n",
    "in the FIRST survey (`first_match_flag = 1`).  \n",
    "\n",
    "In order to get only the best redshift values, we select sources with  \n",
    "`pipeline_redshift_flag = 0`.\n",
    "\n",
    "Thus, we can use 9161 objects from the catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hdu_list = fits.open(cat_path + 'tables_matches_milli_sdss_apr.fits');\n",
    "#sdss_milli  = Table(hdu_list[1].data);\n",
    "#hdu_list.close();\n",
    "\n",
    "sdss_milli = Table.read(cat_path + 'tables_matches_milli_sdss_apr.fits')\n",
    "\n",
    "L_14GHz_filter = np.array((sdss_milli['L_14GHz'] > 0.0) * (sdss_milli['first_offset'] < 1.0)) ;  # sdss + milliquasar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load data from the VLA-COSMOS 3 GHz Large Project\n",
    "**Smolčić et al. 2017**\n",
    "\n",
    "We can, also, separate sources which have an AGN X-ray counterpart\n",
    "with the flag `cosm_xray_flag`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdu_cosmos          = fits.open(cat_path + 'vla_xmmcosmos_smolcic.fits')\n",
    "# cosmos_data         = Table(hdu_cosmos[1].data)\n",
    "# hdu_cosmos.close()\n",
    "\n",
    "cosmos_data         = Table.read(cat_path + 'vla_xmmcosmos_smolcic.fits')\n",
    "\n",
    "x_ray_flag          = cosmos_data['cosm_xray_flag']\n",
    "redshift_cosmos     = cosmos_data['cosm_z']\n",
    "redshift_cosmos[~np.isfinite(redshift_cosmos)] = 0.0  # Repair NaN values\n",
    "int_14GHz_cosmos    = cosmos_data['cosm_lum_14ghz']  # Using their own spectral indices\n",
    "cosmos_3GHz_flux    = cosmos_data['cosm_f_3ghz']  # mJy\n",
    "cosmos_3GHz_flux_e  = cosmos_data['cosm_f_3ghz_err']\n",
    "cosmos_3GHz_flux_e[~np.isfinite(cosmos_3GHz_flux_e)] = 0.0  # Repair NaN values\n",
    "cosmos_14GHz_flux   = cosmos_3GHz_flux_e * (3/1.4)**alpha_used\n",
    "cosmos_14GHz_flux[~np.isfinite(cosmos_14GHz_flux)] = 0.0  # Repair NaN values\n",
    "cosmos_14GHz_flux_e = np.abs(cosmos_14GHz_flux) * cosmos_3GHz_flux_e / cosmos_3GHz_flux\n",
    "lum_dist_cosmos     = cosmos_data['D_lum']  # in m\n",
    "lum_dist_cosmos[~np.isfinite(lum_dist_cosmos)] = 0.0  # Repair NaN values\n",
    "\n",
    "redshift_cosmos_x   = cosmos_data['cosm_z'][(cosmos_data['cosm_z'] > 0) * (cosmos_data['cosm_xray_flag'] == 'T')]\n",
    "int_14GHz_cosmos_x  = cosmos_data['cosm_lum_14ghz'][(cosmos_data['cosm_z'] > 0) * (cosmos_data['cosm_xray_flag'] == 'T')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want, also, to add $z > 6$ QSOs from the list in  \n",
    "Table 3 in the review of **Inayoshi, Visbal, and Haiman, 2020**.  \n",
    "Six of them have $z > 7$\n",
    "\n",
    "Not all of them have $1.4$ GHz measurements. Others have  \n",
    "measurements in different frequencies which can be translated  \n",
    "into the desired frequency using, for instance, the relation  \n",
    "from **Butler et al., 2018**:\n",
    "\n",
    "$$S_{a} = S_{b} \\times (\\frac{\\nu_{b}}{\\nu_{a}})^{\\alpha}$$  \n",
    "\n",
    "We load the data from these sources. Fluxes from different frequencies than $1.4$ GHz are translated to the needed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_z_ra        = np.char.replace(np.loadtxt(cat_path + 'high_z_qso_props.csv', usecols=[1],  dtype='str', delimiter=';'), ',', '.').astype(np.float)\n",
    "high_z_dec       = np.char.replace(np.loadtxt(cat_path + 'high_z_qso_props.csv', usecols=[2],  dtype='str', delimiter=';'), ',', '.').astype(np.float)\n",
    "high_z_zs        = np.char.replace(np.loadtxt(cat_path + 'high_z_qso_props.csv', usecols=[3],  dtype='str', delimiter=';'), ',', '.').astype(np.float)\n",
    "high_z_zs_e      = np.char.replace(np.loadtxt(cat_path + 'high_z_qso_props.csv', usecols=[4],  dtype='str', delimiter=';'), ',', '.').astype(np.float)\n",
    "high_z_14GHz     = np.char.replace(np.loadtxt(cat_path + 'high_z_qso_props.csv', usecols=[6],  dtype='str', delimiter=';'), ',', '.').astype(np.float)\n",
    "high_z_14GHz_e   = np.char.replace(np.loadtxt(cat_path + 'high_z_qso_props.csv', usecols=[7],  dtype='str', delimiter=';'), ',', '.').astype(np.float)\n",
    "high_z_3GHz      = np.char.replace(np.loadtxt(cat_path + 'high_z_qso_props.csv', usecols=[8],  dtype='str', delimiter=';'), ',', '.').astype(np.float)\n",
    "high_z_3GHz_e    = np.char.replace(np.loadtxt(cat_path + 'high_z_qso_props.csv', usecols=[9],  dtype='str', delimiter=';'), ',', '.').astype(np.float)\n",
    "high_z_15GHz     = np.char.replace(np.loadtxt(cat_path + 'high_z_qso_props.csv', usecols=[10], dtype='str', delimiter=';'), ',', '.').astype(np.float)\n",
    "high_z_15GHz_e   = np.char.replace(np.loadtxt(cat_path + 'high_z_qso_props.csv', usecols=[11], dtype='str', delimiter=';'), ',', '.').astype(np.float)\n",
    "high_z_250GHz    = np.char.replace(np.loadtxt(cat_path + 'high_z_qso_props.csv', usecols=[12], dtype='str', delimiter=';'), ',', '.').astype(np.float)\n",
    "high_z_250GHz_e  = np.char.replace(np.loadtxt(cat_path + 'high_z_qso_props.csv', usecols=[13], dtype='str', delimiter=';'), ',', '.').astype(np.float)\n",
    "high_z_mass_1450 = np.char.replace(np.loadtxt(cat_path + 'high_z_qso_props.csv', usecols=[14], dtype='str', delimiter=';'), ',', '.').astype(np.float)\n",
    "high_z_names     = np.loadtxt('high_z_qso_props.csv', usecols=[0], dtype='str', delimiter=';')\n",
    "high_z_lum_d     = luminosity_distance(high_z_zs) * 3.086e22  # in m\n",
    "high_z_up_lim    = np.array([val == '<' for val in np.loadtxt('high_z_qso_props.csv', usecols=[5], dtype='str', delimiter=';')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accumulate values into one array except 250GHz data.  \n",
    "Millimetre luminosities will be used separately since we cannot be completely  \n",
    "sure that they represent, fully, non-thermal emission (from AGN) and not dust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_z_14   = high_z_14GHz + high_z_3GHz + high_z_15GHz\n",
    "high_z_14_e = high_z_14GHz_e + high_z_3GHz_e + high_z_15GHz_e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complement the dataset, we also load four $z > 5.5$ sources which  \n",
    "come from the `radio` catalog in the `Heasarc` database.  \n",
    "We queried the objects which have $1.4$ GHz observations that  \n",
    "are within a $2.5$ arcsec of an object from the `SDSS QUASAR DR12`  \n",
    "catalog. We discard the sources that are already included in the `FIRST`  \n",
    "catalog, to avoid repetition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enlarge the size of the sample, we can also query  \n",
    "the same sample, but extending the redshift range to all positive  \n",
    "values. We can include, too, the exclusion of ***low quality*** redshift_values (or not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdu_radio_z_55       = fits.open(cat_path + 'radio_cat_sdss_z_55.fits');  # high redshift\n",
    "# hdu_radio_z_all_spec = fits.open(cat_path + 'radio_cat_sdss_z_all_spec.fits');  # all redshift, high z quality\n",
    "#hdu_radio_z_all_all  = fits.open(cat_path + 'radio_cat_sdss_z_all_all.fits');  # all redshift, all z quality\n",
    "# radio_sources        = Table(hdu_radio_z_55[1].data);\n",
    "# radio_sources        = Table(hdu_radio_z_all_spec[1].data);\n",
    "# hdu_radio_z_55.close();\n",
    "# hdu_radio_z_all_spec.close();\n",
    "# hdu_radio_z_all_all.close();\n",
    "\n",
    "# radio_sources        = Table.read(cat_path + 'radio_cat_sdss_z_55_spec.fits')       # high redshift\n",
    "radio_sources        = Table.read(cat_path + 'radio_cat_sdss_z_all_spec.fits')      # all redshift, high z quality\n",
    "# radio_sources        = Table.read(cat_path + 'radio_cat_sdss_z_all_all_spec.fits')  # all redshift, all z quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate luminosities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate luminosities (in W/Hz) for different datasets  \n",
    "using the expression\n",
    "\n",
    "$$L_{1.4\\mathrm{GHz}} = 4 \\pi \\mathrm{d}^{2}_{L} f_{1.4\\mathrm{GHz}} (1 + z)^{\\alpha - 1}$$\n",
    "\n",
    "which comes from Alexander et al. 2003\n",
    "\n",
    "We can also obtain that luminosity from the flux in $3$ GHz as\n",
    "\n",
    "$$L_{1.4\\mathrm{GHz}} = 4 \\pi \\mathrm{d}^{2}_{L} {(\\frac{3}{1.4})}^{\\alpha} f_{3\\mathrm{GHz}} (1 + z)^{\\alpha - 1}$$\n",
    "\n",
    "This expression comes from Delhaize et al. 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_21cm           = 4 * np.pi * (sdss_milli['D_lum'][L_14GHz_filter])**2 * sdss_milli['flux_20_cm'][L_14GHz_filter] * 1e-3 * 1e-26 * (1 + sdss_milli['redshift'][L_14GHz_filter])**(alpha_used - 1)\n",
    "L_21cm_e         = np.abs(L_21cm) / sdss_milli['snr_20_cm'][L_14GHz_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_21cm_radio     = 4 * np.pi * (radio_sources['D_lum'])**2 * radio_sources['radio_flux'] * 1e-3 * 1e-26 * (1 + radio_sources['sdss_z'])**(alpha_used - 1)\n",
    "L_21cm_radio_e   = np.abs(L_21cm_radio) * radio_sources['radio_flux_err'] / radio_sources['radio_flux']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rcarvajalp/.anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "L_14GHz_cosmos   = 4 * np.pi * (lum_dist_cosmos)**2 * cosmos_14GHz_flux * 1e-3 * 1e-26 * (1 + redshift_cosmos)**(alpha_used - 1)\n",
    "L_14GHz_cosmos_e = np.abs(L_14GHz_cosmos) * cosmos_14GHz_flux_e / cosmos_14GHz_flux;\n",
    "L_14GHz_cosmos_e[~np.isfinite(L_14GHz_cosmos_e)] = 0.0  # Repair (make zero) error values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_z_lum_14    = 4 * np.pi * high_z_lum_d**2 * high_z_14GHz  * 1e-6 * 1e-26 * (1 + high_z_zs)**(alpha_used - 1)\n",
    "high_z_lum_3     = 4 * np.pi * high_z_lum_d**2 * high_z_3GHz   * 1e-6 * 1e-26 * (1 + high_z_zs)**(alpha_used - 1) * (3/1.4)**alpha_used\n",
    "high_z_lum_15    = 4 * np.pi * high_z_lum_d**2 * high_z_15GHz  * 1e-6 * 1e-26 * (1 + high_z_zs)**(alpha_used - 1) * (1.5/1.4)**alpha_used\n",
    "high_z_lum_250   = 4 * np.pi * high_z_lum_d**2 * high_z_250GHz * 1e-6 * 1e-26 * (1 + high_z_zs)**(alpha_used - 1) * (250/1.4)**(alpha_used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mix all luminosities (different bands) to obtain single value (adding zeroes).  \n",
    "Millimetre luminosities will be used separately since we cannot be completely  \n",
    "sure that they represent, fully, non-thermal emission (from AGN) and not dust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_z_lum_14GHz   = high_z_lum_14 + high_z_lum_3 + high_z_lum_15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also determine error values for these luminosities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_z_lum_14GHz_e  = np.zeros_like(high_z_lum_14GHz)\n",
    "high_z_lum_250GHz_e = np.zeros_like(high_z_lum_250)\n",
    "for counter, element in enumerate(high_z_lum_14GHz):\n",
    "    if element == 0: continue\n",
    "    high_z_lum_14GHz_e[counter] = np.abs(element) * high_z_14_e[counter] / high_z_14[counter]\n",
    "for counter, element in enumerate(high_z_lum_250):\n",
    "    if element == 0: continue\n",
    "    high_z_lum_250GHz_e[counter] = np.abs(element) * high_z_250GHz_e[counter] / high_z_250GHz[counter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a filter to plot, when needed, only the sources which  \n",
    "have mm data but not radio observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_250GHz = np.array((high_z_lum_250 > 0) * (high_z_lum_14GHz == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the points we are interested in. Our sample from **Inayoshi et al., 2020** and the  \n",
    "sources from **SDSS+FIRST** with $z>5.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option to display the data is, instead of showing redshift in the  \n",
    "horizontal axis, have the mass of the observed objects.\n",
    "\n",
    "**Inayoshi et al., 2020** use the rest-frame UV magnitude $\\mathrm{M}_{1450}$  \n",
    "to calculate the mass as:\n",
    "\n",
    "$$M = 10^{[-(\\mathrm{M}_{1450} + 3.459) / 2.5]} [\\mathrm{M}_{\\odot}]$$\n",
    "\n",
    "which yields, on average, the published virial mass estimates for those available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create formal arrays from catalogs to merge them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays from `SDSS+FIRST`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limit_z_sdss          = 5.5\n",
    "limit_z_sdss          = 0.0\n",
    "filter_sdss_z         = np.array(sdss_milli['redshift'][L_14GHz_filter] > limit_z_sdss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_sdss_L          = L_21cm[filter_sdss_z]\n",
    "upper_sdss_L_e        = L_21cm_e[filter_sdss_z]\n",
    "upper_sdss_u_lim      = np.zeros_like(upper_sdss_L, dtype=np.bool)\n",
    "upper_sdss            = sdss_milli[np.array(sdss_milli['redshift'] > limit_z_sdss) * L_14GHz_filter]\n",
    "upper_sdss_ra         = upper_sdss['sdss_ra']\n",
    "upper_sdss_dec        = upper_sdss['sdss_dec']\n",
    "upper_sdss_z          = upper_sdss['redshift']\n",
    "upper_sdss_z_e        = upper_sdss['redshift_err']\n",
    "upper_sdss_f_20cm     = upper_sdss['flux_20_cm']  # mJy\n",
    "upper_sdss_f_20cm_e   = upper_sdss['flux_20_cm'] / upper_sdss['snr_20_cm']  # mJy\n",
    "upper_sdss_f_250GHz   = np.zeros_like(upper_sdss_L)\n",
    "upper_sdss_f_250GHz_e = np.zeros_like(upper_sdss_L)\n",
    "upper_sdss_L_250GHz   = np.zeros_like(upper_sdss_L)\n",
    "upper_sdss_L_250GHz_e = np.zeros_like(upper_sdss_L)\n",
    "upper_sdss_mass_1450  = np.zeros_like(upper_sdss_L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays from the `COSMOS` Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upper_cosmos_L          = int_14GHz_cosmos[np.array(cosmos_data['cosm_z'] > limit_z_sdss)]  # Calculated by them\n",
    "upper_cosmos_L          = L_14GHz_cosmos[np.array(redshift_cosmos > limit_z_sdss)]  # Calculated with our spectral index\n",
    "upper_cosmos_L_e        = L_14GHz_cosmos_e[np.array(redshift_cosmos > limit_z_sdss)]\n",
    "upper_cosmos_u_lim      = np.zeros_like(upper_cosmos_L, dtype=np.bool)\n",
    "upper_cosmos            = cosmos_data[np.array(redshift_cosmos > limit_z_sdss)]\n",
    "upper_cosmos_ra         = upper_cosmos['cosm_ra']\n",
    "upper_cosmos_dec        = upper_cosmos['cosm_dec']\n",
    "upper_cosmos_z          = upper_cosmos['cosm_z']\n",
    "upper_cosmos_z_e        = np.zeros_like(upper_cosmos_L)\n",
    "upper_cosmos_f_20cm     = cosmos_14GHz_flux[np.array(redshift_cosmos > limit_z_sdss)]  # mJy\n",
    "upper_cosmos_f_20cm_e   = cosmos_14GHz_flux_e[np.array(redshift_cosmos > limit_z_sdss)]  # mJy\n",
    "upper_cosmos_f_250GHz   = np.zeros_like(upper_cosmos_L)\n",
    "upper_cosmos_f_250GHz_e = np.zeros_like(upper_cosmos_L)\n",
    "upper_cosmos_L_250GHz   = np.zeros_like(upper_cosmos_L)\n",
    "upper_cosmos_L_250GHz_e = np.zeros_like(upper_cosmos_L)\n",
    "upper_cosmos_mass_1450  = np.zeros_like(upper_cosmos_L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays from `radio`catalog (`Heasarc`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "radio_sdss_ra         = radio_sources['sdss_ra']\n",
    "radio_sdss_dec        = radio_sources['sdss_dec']\n",
    "radio_sdss_u_lim      = np.zeros_like(L_21cm_radio, dtype=np.bool)\n",
    "radio_sdss_z          = radio_sources['sdss_z']\n",
    "radio_sdss_z_e        = radio_sources['sdss_z_err']\n",
    "radio_sdss_f_20cm     = radio_sources['radio_flux']\n",
    "radio_sdss_f_20cm_e   = radio_sources['radio_flux_err']\n",
    "radio_sdss_f_250GHz   = np.zeros_like(L_21cm_radio)\n",
    "radio_sdss_f_250GHz_e = np.zeros_like(L_21cm_radio)\n",
    "radio_sdss_L_250GHz   = np.zeros_like(L_21cm_radio)\n",
    "radio_sdss_L_250GHz_e = np.zeros_like(L_21cm_radio)\n",
    "radio_sdss_mass_1450  = np.zeros_like(L_21cm_radio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging `SDSS+FIRST` and `radio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "radio_large_sample_ra         = np.append(upper_sdss_ra,         radio_sdss_ra)          # deg\n",
    "radio_large_sample_dec        = np.append(upper_sdss_dec,        radio_sdss_dec)         # deg\n",
    "radio_large_sample_L          = np.append(upper_sdss_L,          L_21cm_radio)           # W/Hz\n",
    "radio_large_sample_L_e        = np.append(upper_sdss_L_e,        L_21cm_radio_e)         # W/Hz\n",
    "radio_large_sample_u_lim      = np.append(upper_sdss_u_lim,      radio_sdss_u_lim)\n",
    "radio_large_sample_L_250GHz   = np.append(upper_sdss_L_250GHz,   radio_sdss_L_250GHz)    # W/Hz\n",
    "radio_large_sample_L_250GHz_e = np.append(upper_sdss_L_250GHz_e, radio_sdss_L_250GHz_e)  # W/Hz\n",
    "radio_large_sample_f_20cm     = np.append(upper_sdss_f_20cm,     radio_sdss_f_20cm)      # mJy\n",
    "radio_large_sample_f_20cm_e   = np.append(upper_sdss_f_20cm_e,   radio_sdss_f_20cm_e)    # mJy\n",
    "radio_large_sample_f_250GHz   = np.append(upper_sdss_f_250GHz,   radio_sdss_f_250GHz)    # mJy\n",
    "radio_large_sample_f_250GHz_e = np.append(upper_sdss_f_250GHz_e, radio_sdss_f_250GHz_e)  # mJy\n",
    "radio_large_sample_z          = np.append(upper_sdss_z,          radio_sdss_z)\n",
    "radio_large_sample_z_e        = np.append(upper_sdss_z_e,        radio_sdss_z_e)\n",
    "radio_large_sample_mass_1450  = np.append(upper_sdss_mass_1450,  radio_sdss_mass_1450)   # M_sun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging `SDSS+FIRST`+`radio` and the catalog from **Inayoshi et al., 2020**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_sample_ra        = np.append(radio_large_sample_ra,         high_z_ra[np.array(high_z_lum_14GHz>0)])               # deg\n",
    "medium_sample_dec       = np.append(radio_large_sample_dec,        high_z_dec[np.array(high_z_lum_14GHz>0)])              # deg\n",
    "medium_sample_L         = np.append(radio_large_sample_L,          high_z_lum_14GHz[np.array(high_z_lum_14GHz>0)])        # W/Hz\n",
    "medium_sample_L_e       = np.append(radio_large_sample_L_e,        high_z_lum_14GHz_e[np.array(high_z_lum_14GHz>0)])      # W/Hz\n",
    "medium_sample_u_lim     = np.append(radio_large_sample_u_lim,      high_z_up_lim[np.array(high_z_lum_14GHz>0)])\n",
    "medium_sample_L_250     = np.append(radio_large_sample_L_250GHz,   high_z_lum_250[np.array(high_z_lum_14GHz>0)])          # W/Hz\n",
    "medium_sample_L_250_e   = np.append(radio_large_sample_L_250GHz_e, high_z_lum_250GHz_e[np.array(high_z_lum_14GHz>0)])     # W/Hz\n",
    "medium_sample_f20cm     = np.append(radio_large_sample_f_20cm,     high_z_14[np.array(high_z_lum_14GHz>0)] * 1e-3)        # mJy\n",
    "medium_sample_f20cm_e   = np.append(radio_large_sample_f_20cm_e,   high_z_14_e[np.array(high_z_lum_14GHz>0)] * 1e-3)      # mJy\n",
    "medium_sample_f250GHz   = np.append(radio_large_sample_f_250GHz,   high_z_250GHz[np.array(high_z_lum_14GHz>0)] * 1e-3)    # mJy\n",
    "medium_sample_f250GHz_e = np.append(radio_large_sample_f_250GHz_e, high_z_250GHz_e[np.array(high_z_lum_14GHz>0)] * 1e-3)  # mJy\n",
    "medium_sample_z         = np.append(radio_large_sample_z,          high_z_zs[np.array(high_z_lum_14GHz>0)])\n",
    "medium_sample_z_e       = np.append(radio_large_sample_z_e,        high_z_zs_e[np.array(high_z_lum_14GHz>0)])\n",
    "medium_sample_mass_1450 = np.append(radio_large_sample_mass_1450,  high_z_mass_1450[np.array(high_z_lum_14GHz>0)])        # M_sun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging `SDSS+FIRST`+`radio`+**Inayoshi et al., 2020** and `COSMOS` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_sample_ra        = np.append(medium_sample_ra,        upper_cosmos_ra)          # deg\n",
    "large_sample_dec       = np.append(medium_sample_dec,       upper_cosmos_dec)         # deg\n",
    "large_sample_L         = np.append(medium_sample_L,         upper_cosmos_L)           # W/Hz\n",
    "large_sample_L_e       = np.append(medium_sample_L_e,       upper_cosmos_L_e)         # W/Hz\n",
    "large_sample_u_lim     = np.append(medium_sample_u_lim,     upper_cosmos_u_lim)\n",
    "large_sample_L_250     = np.append(medium_sample_L_250,     upper_cosmos_L_250GHz)    # W/Hz\n",
    "large_sample_L_250_e   = np.append(medium_sample_L_250_e,   upper_cosmos_L_250GHz_e)  # W/Hz\n",
    "large_sample_f20cm     = np.append(medium_sample_f20cm,     upper_cosmos_f_20cm)      # mJy\n",
    "large_sample_f20cm_e   = np.append(medium_sample_f20cm_e,   upper_cosmos_f_20cm_e)    # mJy\n",
    "large_sample_f250GHz   = np.append(medium_sample_f250GHz,   upper_cosmos_f_250GHz)    # mJy\n",
    "large_sample_f250GHz_e = np.append(medium_sample_f250GHz_e, upper_cosmos_f_250GHz_e)  # mJy\n",
    "large_sample_z         = np.append(medium_sample_z,         upper_cosmos_z)\n",
    "large_sample_z_e       = np.append(medium_sample_z_e,       upper_cosmos_z_e)\n",
    "large_sample_mass_1450 = np.append(medium_sample_mass_1450, upper_cosmos_mass_1450)   # M_sun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we also want to obtain more properties from the selected  \n",
    "sources (**Inayoshi et al., 2020** + **SDSS+FIRST**). We will use `astroquery` to  \n",
    "obtain information from `simbad`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we obtain the names and coordinates of our sources to query them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_radio_sdss    = np.append(radio_sources['sdss_name'], upper_sdss['name'])\n",
    "medium_sample_names = np.append(names_radio_sdss, upper_cosmos['cosm_name'])\n",
    "large_sample_names  = np.append(medium_sample_names, high_z_names[np.array(high_z_lum_14GHz>0)])\n",
    "large_sample_coords = SkyCoord(ra=large_sample_ra, dec=large_sample_dec, unit=(u.deg, u.deg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we correct/change the names for those which can be looked up in `Simbad` and `Ned`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_to_replace = ['SDSS J125507.61+463126.5', 'SDSS J160558.86+474300.1', 'SDSS J111036.32+481752.3', 'SDSS J163033.89+401209.6']\n",
    "new_to_replace = ['NVSS J125507+463128', '2MASS J16055893+4742596', 'NVSS J111036+481753', 'SDSS J163033.90+401209.6']\n",
    "\n",
    "for old, new in zip(old_to_replace, new_to_replace):\n",
    "    index = np.where(large_sample_names == old)\n",
    "    large_sample_names[index] = new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can query the database to obtain the desired data.  In this point,  \n",
    "we also add more columns to be queried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_simbad_flag               = False\n",
    "load_simbad_flag                = False\n",
    "create_simbad_inayoshi_flag     = False\n",
    "read_simbad_inayoshi_flag       = False\n",
    "query_ned_names_flag            = False\n",
    "query_ned_photometry_flag       = False\n",
    "order_ned_photometry_flag       = False\n",
    "create_simbad_inayoshi_ned_flag = False\n",
    "read_simbad_inayoshi_ned_flag   = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_simbad_flag:\n",
    "    customSimbad   = Simbad()\n",
    "    initial_fields = customSimbad.get_votable_fields()\n",
    "\n",
    "    if 'coordinates' in initial_fields:\n",
    "        customSimbad.remove_votable_fields('coordinates')\n",
    "        customSimbad.add_votable_fields('ra(d)', 'dec(d)')\n",
    "    if 'z_value' not in initial_fields:\n",
    "        customSimbad.add_votable_fields('z_value')\n",
    "    for band in ['B','V','R','I','J','K']:\n",
    "        if f'fluxdata({band})' not in initial_fields:\n",
    "            customSimbad.add_votable_fields(f'flux({band})', f'flux_error({band})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All sources but those from `COSMOS` catalog have meaningful (for `simbad`) names.  \n",
    "Thus, separate queries will be executed. And, to standardize results, queries  \n",
    "will only be based on coordinates (not names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_simbad_flag:\n",
    "    limit_set            = int(np.floor(np.shape(medium_sample_L)[0]/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_simbad_flag:\n",
    "    result_table_simbad  = Table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_table = customSimbad.query_objects(large_sample_names)\n",
    "# customSimbad.TIMEOUT = 240\n",
    "\n",
    "# result_table_job_a   = customSimbad.query_objects(large_sample_names[:limit_set])\n",
    "\n",
    "# result_table_job_b   = customSimbad.query_objects(large_sample_names[limit_set:(limit_set*2)])\n",
    "\n",
    "# result_table_job_c   = customSimbad.query_objects(large_sample_names[(limit_set*2):(limit_set*3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_simbad_flag:\n",
    "    query_error = 0\n",
    "    final_error = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_simbad_flag:\n",
    "    with progressbar.ProgressBar(min_value=0, max_value=(limit_set - 1)) as bar:\n",
    "        for index, coord in enumerate(large_sample_coords[:limit_set]):\n",
    "            temp_table      = Table()\n",
    "            try:\n",
    "                temp_table      = customSimbad.query_region(coord, radius=2.0*u.arcsec)\n",
    "                if len(temp_table) == 0:\n",
    "                    temp_table      = Table(names=('RA_d', 'DEC_d'), dtype=(result_table_simbad['RA_d'].info.dtype, result_table_simbad['DEC_d'].info.dtype))\n",
    "                    temp_table.add_row((coord.ra.deg, coord.dec.deg))\n",
    "                temp_table.meta['description'] = 'Simbad_q'\n",
    "            except:\n",
    "                temp_table      = Table(names=('RA_d', 'DEC_d'), dtype=(result_table_simbad['RA_d'].info.dtype, result_table_simbad['DEC_d'].info.dtype))\n",
    "                temp_table.add_row((coord.ra.deg, coord.dec.deg))\n",
    "                temp_table.meta['description'] = 'Simbad_q'\n",
    "                #print(f'Error with element {(index)} of the sample')\n",
    "                query_error += 1\n",
    "            try:\n",
    "                if temp_table['RA_d'].unit != 'deg':\n",
    "                    replacement_col     = MaskedColumn(temp_table['RA_d'].data, dtype=result_table_simbad['RA_d'].dtype, unit=result_table_simbad['RA_d'].unit, format=result_table_simbad['RA_d'].format, description=result_table_simbad['RA_d'].description)\n",
    "                    temp_table['RA_d']  = replacement_col\n",
    "                result_table_simbad = vstack([result_table_simbad, temp_table[0]])\n",
    "            except:\n",
    "                print(f'Error with element {(index)} of the sample')\n",
    "                final_error += 1\n",
    "            bar.update(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_simbad_flag:\n",
    "    with progressbar.ProgressBar(min_value=limit_set, max_value=(limit_set*2 - 1)) as bar:\n",
    "        for index, coord in enumerate(large_sample_coords[limit_set:(limit_set*2)]):\n",
    "            temp_table      = Table()\n",
    "            try:\n",
    "                temp_table      = customSimbad.query_region(coord, radius=2.0*u.arcsec)\n",
    "                if len(temp_table) == 0:\n",
    "                    temp_table      = Table(names=('RA_d', 'DEC_d'), dtype=(result_table_simbad['RA_d'].info.dtype, result_table_simbad['DEC_d'].info.dtype))\n",
    "                    temp_table.add_row((coord.ra.deg, coord.dec.deg))\n",
    "                temp_table.meta['description'] = 'Simbad_q'\n",
    "            except:\n",
    "                temp_table      = Table(names=('RA_d', 'DEC_d'), dtype=(result_table_simbad['RA_d'].info.dtype, result_table_simbad['DEC_d'].info.dtype))\n",
    "                temp_table.add_row((coord.ra.deg, coord.dec.deg))\n",
    "                temp_table.meta['description'] = 'Simbad_q'\n",
    "                #print(f'Error with element {(index + limit_set)} of the sample')\n",
    "                query_error += 1\n",
    "            try:\n",
    "                if temp_table['RA_d'].unit != 'deg':\n",
    "                    replacement_col     = MaskedColumn(temp_table['RA_d'].data, dtype=result_table_simbad['RA_d'].dtype, unit=result_table_simbad['RA_d'].unit, format=result_table_simbad['RA_d'].format, description=result_table_simbad['RA_d'].description)\n",
    "                    temp_table['RA_d']  = replacement_col\n",
    "                result_table_simbad = vstack([result_table_simbad, temp_table[0]])\n",
    "            except:\n",
    "                print(f'Error with element {(index + limit_set)} of the sample')\n",
    "                final_error += 1\n",
    "            bar.update(index + limit_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_simbad_flag:\n",
    "    with progressbar.ProgressBar(min_value=(limit_set*2), max_value=(limit_set*3)) as bar:\n",
    "        for index, coord in enumerate(large_sample_coords[(limit_set*2):(limit_set*3 + 1)]):\n",
    "            temp_table      = Table()\n",
    "            try:\n",
    "                temp_table      = customSimbad.query_region(coord, radius=2.0*u.arcsec)\n",
    "                if len(temp_table) == 0:\n",
    "                    temp_table      = Table(names=('RA_d', 'DEC_d'), dtype=(result_table_simbad['RA_d'].info.dtype, result_table_simbad['DEC_d'].info.dtype))\n",
    "                    temp_table.add_row((coord.ra.deg, coord.dec.deg))\n",
    "                temp_table.meta['description'] = 'Simbad_q'\n",
    "            except:\n",
    "                temp_table      = Table(names=('RA_d', 'DEC_d'), dtype=(result_table_simbad['RA_d'].info.dtype, result_table_simbad['DEC_d'].info.dtype))\n",
    "                temp_table.add_row((coord.ra.deg, coord.dec.deg))\n",
    "                temp_table.meta['description'] = 'Simbad_q'\n",
    "                # print(f'Error with element {(index + limit_set*2)} of the sample')\n",
    "                query_error += 1\n",
    "            try:\n",
    "                if temp_table['RA_d'].unit != 'deg':\n",
    "                    replacement_col     = MaskedColumn(temp_table['RA_d'].data, dtype=result_table_simbad['RA_d'].dtype, unit=result_table_simbad['RA_d'].unit, format=result_table_simbad['RA_d'].format, description=result_table_simbad['RA_d'].description)\n",
    "                    temp_table['RA_d']  = replacement_col\n",
    "                result_table_simbad = vstack([result_table_simbad, temp_table[0]])\n",
    "            except:\n",
    "                print(f'Error with element {(index + limit_set*2)} of the sample')\n",
    "                final_error += 1\n",
    "            bar.update(index + limit_set*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query for `COSMOS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_simbad_flag:\n",
    "    limit_set_cosmos = int(np.floor(np.shape(upper_cosmos_L)[0]/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_simbad_flag:\n",
    "    with progressbar.ProgressBar(min_value=(limit_set*3 + 1), max_value=(limit_set*3 + limit_set_cosmos)) as bar:\n",
    "        for index, coord in enumerate(large_sample_coords[(limit_set*3 + 1):(limit_set*3 + 1 + limit_set_cosmos)]):\n",
    "            temp_table      = Table()\n",
    "            try:\n",
    "                temp_table      = customSimbad.query_region(coord, radius=3.0*u.arcsec)\n",
    "                if len(temp_table) == 0:\n",
    "                    temp_table      = Table(names=('RA_d', 'DEC_d'), dtype=(result_table_simbad['RA_d'].info.dtype, result_table_simbad['DEC_d'].info.dtype))\n",
    "                    temp_table.add_row((coord.ra.deg, coord.dec.deg))\n",
    "                temp_table.meta['description'] = 'Simbad_q'\n",
    "            except:\n",
    "                # print(f'Error with element {(index + limit_set*3 + 1)} of the sample')\n",
    "                temp_table      = Table(names=('RA_d', 'DEC_d'), dtype=(result_table_simbad['RA_d'].info.dtype, result_table_simbad['DEC_d'].info.dtype))\n",
    "                temp_table.add_row((coord.ra.deg, coord.dec.deg))\n",
    "                temp_table.meta['description'] = 'Simbad_q'\n",
    "                query_error += 1\n",
    "            try:\n",
    "                if temp_table['RA_d'].unit != 'deg':\n",
    "                    replacement_col     = MaskedColumn(temp_table['RA_d'].data, dtype=result_table_simbad['RA_d'].dtype, unit=result_table_simbad['RA_d'].unit, format=result_table_simbad['RA_d'].format, description=result_table_simbad['RA_d'].description)\n",
    "                    temp_table['RA_d']  = replacement_col\n",
    "                result_table_simbad = vstack([result_table_simbad, temp_table[0]])\n",
    "            except:\n",
    "                print(f'Error with element {(index + limit_set*3 + 1)} of the sample')\n",
    "                temp_table      = Table(names=('RA_d', 'DEC_d'), dtype=(result_table_simbad['RA_d'].info.dtype, result_table_simbad['DEC_d'].info.dtype))\n",
    "                temp_table.add_row((coord.ra.deg, coord.dec.deg))\n",
    "                temp_table.meta['description'] = 'Simbad query for radio objects'\n",
    "                result_table_simbad = vstack([result_table_simbad, temp_table[0]])\n",
    "                final_error += 1\n",
    "            bar.update(index + limit_set*3 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_simbad_flag:\n",
    "    with progressbar.ProgressBar(min_value=(limit_set*3 + 1 + limit_set_cosmos), max_value=(limit_set*3 + limit_set_cosmos*2)) as bar:\n",
    "        for index, coord in enumerate(large_sample_coords[(limit_set*3 + 1 + limit_set_cosmos):(limit_set*3 + 1 + limit_set_cosmos*2)]):\n",
    "            temp_table      = Table()\n",
    "            try:\n",
    "                temp_table      = customSimbad.query_region(coord, radius=3.0*u.arcsec)\n",
    "                if len(temp_table) == 0:\n",
    "                    temp_table      = Table(names=('RA_d', 'DEC_d'), dtype=(result_table_simbad['RA_d'].info.dtype, result_table_simbad['DEC_d'].info.dtype))\n",
    "                    temp_table.add_row((coord.ra.deg, coord.dec.deg))\n",
    "                temp_table.meta['description'] = 'Simbad_q'\n",
    "            except:\n",
    "                temp_table      = Table(names=('RA_d', 'DEC_d'), dtype=(result_table_simbad['RA_d'].info.dtype, result_table_simbad['DEC_d'].info.dtype))\n",
    "                temp_table.add_row((coord.ra.deg, coord.dec.deg))\n",
    "                temp_table.meta['description'] = 'Simbad_q'\n",
    "                # print(f'Error with element {(index + limit_set*3 + 1 + limit_set_cosmos)} of the sample')\n",
    "                query_error += 1\n",
    "            try:\n",
    "                if temp_table['RA_d'].unit != 'deg':\n",
    "                    replacement_col     = MaskedColumn(temp_table['RA_d'].data, dtype=result_table_simbad['RA_d'].dtype, unit=result_table_simbad['RA_d'].unit, format=result_table_simbad['RA_d'].format, description=result_table_simbad['RA_d'].description)\n",
    "                    temp_table['RA_d']  = replacement_col\n",
    "                result_table_simbad = vstack([result_table_simbad, temp_table[0]])\n",
    "            except:\n",
    "                print(f'Error with element {(index + limit_set*3 + 1 + limit_set_cosmos)} of the sample')\n",
    "                temp_table      = Table(names=('RA_d', 'DEC_d'), dtype=(result_table_simbad['RA_d'].info.dtype, result_table_simbad['DEC_d'].info.dtype))\n",
    "                temp_table.add_row((coord.ra.deg, coord.dec.deg))\n",
    "                temp_table.meta['description'] = 'Simbad query for radio objects'\n",
    "                result_table_simbad = vstack([result_table_simbad, temp_table[0]])\n",
    "                final_error += 1\n",
    "            bar.update(index + limit_set*3 + 1 + limit_set_cosmos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_simbad_flag:\n",
    "    with progressbar.ProgressBar(min_value=(limit_set*3 + 1 + limit_set_cosmos*2), max_value=np.shape(large_sample_coords)[0]) as bar:\n",
    "        for index, coord in enumerate(large_sample_coords[(limit_set*3 + 1 + limit_set_cosmos*2):]):\n",
    "            temp_table      = Table()\n",
    "            try:\n",
    "                temp_table      = customSimbad.query_region(coord, radius=3.0*u.arcsec)\n",
    "                if len(temp_table) == 0:\n",
    "                    temp_table      = Table(names=('RA_d', 'DEC_d'), dtype=(result_table_simbad['RA_d'].info.dtype, result_table_simbad['DEC_d'].info.dtype))\n",
    "                    temp_table.add_row((coord.ra.deg, coord.dec.deg))\n",
    "                temp_table.meta['description'] = 'Simbad_q'\n",
    "            except:\n",
    "                temp_table      = Table(names=('RA_d', 'DEC_d'), dtype=(result_table_simbad['RA_d'].info.dtype, result_table_simbad['DEC_d'].info.dtype))\n",
    "                temp_table.add_row((coord.ra.deg, coord.dec.deg))\n",
    "                temp_table.meta['description'] = 'Simbad_q'\n",
    "                # print(f'Error with element {(index + limit_set*3 + 1 + limit_set_cosmos*2)} of the sample')\n",
    "                query_error += 1\n",
    "            try:\n",
    "                if temp_table['RA_d'].unit != 'deg':\n",
    "                    replacement_col     = MaskedColumn(temp_table['RA_d'].data, dtype=result_table_simbad['RA_d'].dtype, unit=result_table_simbad['RA_d'].unit, format=result_table_simbad['RA_d'].format, description=result_table_simbad['RA_d'].description)\n",
    "                    temp_table['RA_d']  = replacement_col\n",
    "                result_table_simbad = vstack([result_table_simbad, temp_table[0]])\n",
    "            except:\n",
    "                print(f'Error with element {(index + limit_set*3 + 1 + limit_set_cosmos*2)} of the sample')\n",
    "                temp_table      = Table(names=('RA_d', 'DEC_d'), dtype=(result_table_simbad['RA_d'].info.dtype, result_table_simbad['DEC_d'].info.dtype))\n",
    "                temp_table.add_row((coord.ra.deg, coord.dec.deg))\n",
    "                temp_table.meta['description'] = 'Simbad query for radio objects'\n",
    "                result_table_simbad = vstack([result_table_simbad, temp_table[0]])\n",
    "                final_error += 1\n",
    "            bar.update(index + limit_set*3 + 1 + limit_set_cosmos*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the query to a file for future executions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_simbad_flag:\n",
    "    result_table_simbad.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_simbad_flag:\n",
    "    result_table_simbad.write('large_cat_simbad_query.csv', format='ascii.csv', overwrite=True, serialize_method='data_mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to create a copy of table to save it as `fits` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_simbad_flag:\n",
    "    copy_simbad_to_write = result_table_simbad\n",
    "    str_id = copy_simbad_to_write['MAIN_ID'].astype('str')\n",
    "    copy_simbad_to_write.replace_column('MAIN_ID', str_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_simbad_flag:\n",
    "    copy_simbad_to_write.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_simbad_flag:\n",
    "    copy_simbad_to_write.write('large_cat_simbad_query.fits', format='fits', overwrite=True, serialize_method='data_mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save running time, we can load the data from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if load_simbad_flag:\n",
    "#    result_table_simbad = Table.read(cat_path + 'large_cat_simbad_query.csv', format='ascii.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_simbad_flag:\n",
    "    result_table_simbad     = Table.read(cat_path + 'large_cat_simbad_query.fits');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_table_simbad.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point, we merge the data from the query to `simbad` with the  \n",
    "values from this notebook (**Inayoshi et al., 2020** and **SDSS+FIRST**).  \n",
    "In order to do this, we convert the data into `astropy` columns, and then  \n",
    "into `astropy` tables. They will be ready to be exported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_simbad_inayoshi_flag:\n",
    "    coords_simbad_inayoshi = SkyCoord(result_table_simbad['RA_d'], result_table_simbad['DEC_d'], unit=u.deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_simbad_inayoshi_flag:\n",
    "    column_cat_index    = MaskedColumn(np.arange(np.shape(large_sample_z)[0]), name='INDEX', dtype='int', description='Index number')\n",
    "    column_cat_name     = MaskedColumn(large_sample_names, name='CAT_NAME', dtype='str', description='Name used in this catalog', mask=np.array(large_sample_names == ''))\n",
    "    column_cat_coords   = MaskedColumn(coords_simbad_inayoshi.to_string('decimal'), name='COORD', dtype='str', description='Merged Coordinates', mask=np.array(coords_simbad_inayoshi.to_string('decimal') == ''))\n",
    "    column_z_own        = MaskedColumn(large_sample_z, name='Z_OWN', unit='', description='Redshift from Inayoshi+2020 or SDSS+FIRST', fill_value=np.nan, mask=np.array(large_sample_z == 0))\n",
    "    column_z_own_err    = MaskedColumn(large_sample_z_e, name='Z_OWN_ERR', unit='', description='Redshift error from Inayoshi+2020 or SDSS+FIRST', fill_value=np.nan, mask=np.array(large_sample_z_e == 0))\n",
    "    column_L_14GHz      = MaskedColumn(large_sample_L, name='L_20CM', unit='W/Hz', description='Luminosity in 1.4 GHz', fill_value=np.nan, mask=np.array(large_sample_L == 0))\n",
    "    column_L_14GHz_err  = MaskedColumn(large_sample_L_e, name='L_20CM_ERR', unit='W/Hz', description='Luminosity error in 1.4 GHz', fill_value=np.nan, mask=np.array(large_sample_L_e == 0))\n",
    "    column_L_14GHz_up   = MaskedColumn(large_sample_u_lim, name='L_20CM_UP_LIM', dtype='bool', description='True if L_20CM is upper limit')\n",
    "    column_L_250GHz     = MaskedColumn(large_sample_L_250, name='L_250GHZ', unit='W/Hz', description='Luminosity in 250 GHz', fill_value=np.nan, mask=np.array(large_sample_L_250 == 0))\n",
    "    column_L_250GHz_err = MaskedColumn(large_sample_L_250_e, name='L_250GHZ_ERR', unit='W/Hz', description='Luminosity error in 250 GHz', fill_value=np.nan, mask=np.array(large_sample_L_250_e == 0))\n",
    "    column_f_20cm       = MaskedColumn(large_sample_f20cm, name='F_20CM', unit='mJy', description='Flux in 20 cm', fill_value=np.nan, mask=np.array(large_sample_f20cm == 0))\n",
    "    column_f_20cm_err   = MaskedColumn(large_sample_f20cm_e, name='F_20CM_ERR', unit='mJy', description='Flux error in 20 cm', fill_value=np.nan, mask=np.array(large_sample_f20cm_e == 0))\n",
    "    column_f_250GHz     = MaskedColumn(large_sample_f250GHz, name='F_250GHZ', unit='mJy', description='Flux in 250 GHz', fill_value=np.nan, mask=np.array(large_sample_f250GHz == 0))\n",
    "    column_f_250GHz_err = MaskedColumn(large_sample_f250GHz_e, name='F_250GHZ_ERR', unit='mJy', description='Flux error in 250 GHz', fill_value=np.nan, mask=np.array(large_sample_f250GHz_e == 0))\n",
    "    column_mass_1450    = MaskedColumn(large_sample_mass_1450, name='MASS_1450', unit='Msun', description='Mass from mag_1450 (UV)', fill_value=np.nan, mask=np.array(large_sample_mass_1450 == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_simbad_inayoshi_flag:\n",
    "    result_table_simbad.add_columns([column_cat_index, column_cat_name, column_cat_coords, column_z_own, column_z_own_err, column_L_14GHz, column_L_14GHz_err, column_L_14GHz_up, column_L_250GHz, column_L_250GHz_err, column_f_20cm, column_f_20cm_err, column_f_250GHz, column_f_250GHz_err, column_mass_1450])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_simbad_inayoshi_flag:\n",
    "    str_id = result_table_simbad['MAIN_ID'].astype('str')\n",
    "    result_table_simbad.replace_column('MAIN_ID', str_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy_table = result_table_simbad.filled(fill_value=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write the table into a file. It can be `.fits`, `.votable`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy_table.write('high_z_qsos.ecsv', format='ascii.ecsv', overwrite=True, serialize_method='data_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: Keyword name 'description' is greater than 8 characters or contains characters not allowed by the FITS standard; a HIERARCH card will be created. [astropy.io.fits.card]\n"
     ]
    }
   ],
   "source": [
    "if create_simbad_inayoshi_flag:\n",
    "    result_table_simbad.write('large_cat_simbad_query_inayoshi.fits', format='fits', overwrite=True, serialize_method='data_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_simbad_inayoshi_flag:\n",
    "    result_table_simbad.write('large_cat_simbad_query_inayoshi.csv', format='ascii.csv', overwrite=True, serialize_method='data_mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save running time, we can load the data from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if read_simbad_inayoshi_flag:\n",
    "#    result_table_simbad = Table.read(cat_path + 'large_cat_simbad_query_inayoshi.csv', format='ascii.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "if read_simbad_inayoshi_flag:\n",
    "    result_table_simbad = Table.read(cat_path + 'large_cat_simbad_query_inayoshi.fits');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Table length=18023>\n",
       "     name      dtype    unit   format                    description                   n_bad\n",
       "------------- ------- ------- -------- ----------------------------------------------- -----\n",
       "      MAIN_ID   str41                                    Main identifier for an object   606\n",
       "         RA_d float64     deg {:11.8f}                                 Right ascension     0\n",
       "        DEC_d float64     deg {:12.8f}                                     Declination     0\n",
       "      Z_VALUE float64         {:16.7f}                                        Redshift  1644\n",
       "       FLUX_B float32     mag                                              Magnitude B  8961\n",
       " FLUX_ERROR_B float32         {:12.3f}                                      flux error 11228\n",
       "       FLUX_V float32     mag                                              Magnitude V  8857\n",
       " FLUX_ERROR_V float32         {:12.3f}                                      flux error 11189\n",
       "       FLUX_R float32     mag                                              Magnitude R 12483\n",
       " FLUX_ERROR_R float32         {:12.3f}                                      flux error 12782\n",
       "       FLUX_I float32     mag                                              Magnitude I 12167\n",
       " FLUX_ERROR_I float32         {:12.3f}                                      flux error 12862\n",
       "       FLUX_J float32     mag                                              Magnitude J 11448\n",
       " FLUX_ERROR_J float32         {:12.3f}                                      flux error 11500\n",
       "       FLUX_K float32     mag                                              Magnitude K  9921\n",
       " FLUX_ERROR_K float32         {:12.3f}                                      flux error 10033\n",
       "        INDEX   int64                                                     Index number     0\n",
       "     CAT_NAME   str34                                        Name used in this catalog     0\n",
       "        COORD   str19                                               Merged Coordinates     0\n",
       "        Z_OWN float64                        Redshift from Inayoshi+2020 or SDSS+FIRST     0\n",
       "    Z_OWN_ERR float64                  Redshift error from Inayoshi+2020 or SDSS+FIRST  9373\n",
       "       L_20CM float64  W / Hz                                    Luminosity in 1.4 GHz    66\n",
       "   L_20CM_ERR float64  W / Hz                              Luminosity error in 1.4 GHz    66\n",
       "L_20CM_UP_LIM    bool                                    True if L_20CM is upper limit     0\n",
       "     L_250GHZ float64  W / Hz                                    Luminosity in 250 GHz 18010\n",
       " L_250GHZ_ERR float64  W / Hz                              Luminosity error in 250 GHz 18010\n",
       "       F_20CM float64     mJy                                            Flux in 20 cm    66\n",
       "   F_20CM_ERR float64     mJy                                      Flux error in 20 cm    66\n",
       "     F_250GHZ float64     mJy                                          Flux in 250 GHz 18010\n",
       " F_250GHZ_ERR float64     mJy                                    Flux error in 250 GHz 18010\n",
       "    MASS_1450 float64 solMass                                  Mass from mag_1450 (UV) 18006"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table_simbad.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the objects of the table in other catalogs and services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from astroquery.heasarc import Heasarc\n",
    "#Heasarc.query_mission_cols(mission='radio')\n",
    "#tabb = Heasarc.query(large_sample_names, mission='radio', timeout=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "customNed        = Ned()\n",
    "fields_to_remove = ['No.', 'Photometry Measurement', 'Uncertainty', 'Units', 'Significance', 'Published frequency', 'Frequency Mode', 'Coordinates Targeted', 'Spatial Mode', 'Qualifiers', 'Comments']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying sources with name in `Ned`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty_counter = 0\n",
    "# res_tab       = {}\n",
    "# for name in large_sample_names:\n",
    "#     try:\n",
    "#         res_tab[name] = customNed.get_table(name, output_table_format=1)\n",
    "#         res_tab[name].remove_columns(fields_to_remove)\n",
    "#     except:\n",
    "#         res_tab[name] = Table()\n",
    "#         empty_counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can do it with coordinates.  \n",
    "\n",
    "First, we query the coordinates. If we found something,  \n",
    "we use the name of the source to obtain it photometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_simbad_inayoshi = SkyCoord(result_table_simbad['RA_d'], result_table_simbad['DEC_d'], unit=u.deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_tab_name_counter  = 0\n",
    "empty_tab_photo_counter = 0\n",
    "error_tab_name_counter  = 0\n",
    "error_tab_photo_counter = 0\n",
    "ned_tables              = {}\n",
    "ned_info                = {}\n",
    "ned_names               = []\n",
    "#ned_names               = np.array([''  for x in np.arange(np.shape(large_sample_names)[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (18023 of 18023) |##################| Elapsed Time: 0:14:13 Time:  0:14:13\n"
     ]
    }
   ],
   "source": [
    "if query_ned_names_flag:\n",
    "    with progressbar.ProgressBar(min_value=0, max_value=np.shape(coords_simbad_inayoshi)[0]) as bar:\n",
    "        for index, coord in enumerate(coords_simbad_inayoshi):\n",
    "            try:\n",
    "                init_table            = customNed.query_region(coords_simbad_inayoshi[index], radius=3.0*u.arcsec)\n",
    "                if len(init_table) == 0:\n",
    "                    init_table        = Table(names=('Object Name', 'RA', 'DEC'), dtype=('str', 'float', 'float'), masked=True)\n",
    "                    init_table.add_row(('No Name', coords_simbad_inayoshi[index].ra.deg, coords_simbad_inayoshi[index].dec.deg), mask=[True, False, False])\n",
    "                    ned_info[index]   = init_table\n",
    "                    ned_names.append('No Name')\n",
    "                    empty_tab_name_counter += 1\n",
    "                    continue\n",
    "                init_table.remove_columns(['Magnitude and Filter', 'Positions', 'Diameter Points'])\n",
    "                ned_info[index]   = init_table\n",
    "                used_source_idx   = np.nanargmin(init_table['Separation'])  # Index of element with lowest separation from coords\n",
    "                init_name         = init_table['Object Name'][used_source_idx]\n",
    "                # ned_names[index]  = init_name\n",
    "                ned_names.append(init_name)\n",
    "            except:\n",
    "                init_table        = Table(names=('Object Name', 'RA', 'DEC'), dtype=('str', 'float', 'float'), masked=True)\n",
    "                init_table.add_row(('No Name', coords_simbad_inayoshi[index].ra.deg, coords_simbad_inayoshi[index].dec.deg), mask=[True, False, False])\n",
    "                ned_info[index]   = init_table\n",
    "                ned_names.append('No Name')\n",
    "                error_tab_name_counter += 1\n",
    "            bar.update(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ned_names = np.array(ned_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ned_redshifts = []\n",
    "for key in ned_info:\n",
    "    ned_redshifts.append(ned_info[index]['Redshift'])\n",
    "ned_redshifts = np.array(ned_redshifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_count = 0\n",
    "indices_non   = []\n",
    "for index, name in enumerate(ned_names):\n",
    "    if name != 'No Name':\n",
    "        counter_count += 1\n",
    "for index, name in enumerate(ned_names):\n",
    "    if name == 'No Name':\n",
    "        indices_non.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (18023 of 18023) |##################| Elapsed Time: 0:05:11 Time:  0:05:11\n"
     ]
    }
   ],
   "source": [
    "if query_ned_photometry_flag:\n",
    "    with progressbar.ProgressBar(min_value=0, max_value=np.shape(ned_names)[0]) as bar:\n",
    "        for index, name in enumerate(ned_names):\n",
    "            try:\n",
    "                if name == 'No Name':\n",
    "                    phot_table        = Table(names=('Observed Passband',), dtype=('str',), masked=True)\n",
    "                    phot_table.add_row(('No Passband',), mask=(True,))\n",
    "                    ned_tables[index] = phot_table\n",
    "                    empty_tab_photo_counter += 1\n",
    "                    continue\n",
    "                phot_table            = customNed.get_table(name, table='photometry', output_table_format=3)\n",
    "                phot_table.remove_columns(fields_to_remove)\n",
    "                ned_tables[index]     = phot_table\n",
    "            except:\n",
    "                phot_table            = Table(names=('Observed Passband',), dtype=('str',), masked=True)\n",
    "                phot_table.add_row(('No Passband',), mask=(True,))\n",
    "                ned_tables[index]     = phot_table\n",
    "                error_tab_photo_counter += 1\n",
    "            bar.update(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Observed Passband',\n",
       " 'Frequency',\n",
       " 'Flux Density',\n",
       " 'Upper limit of uncertainty',\n",
       " 'Lower limit of uncertainty',\n",
       " 'Upper limit of Flux Density',\n",
       " 'Lower limit of Flux Density',\n",
       " 'NED Uncertainty',\n",
       " 'NED Units',\n",
       " 'Refcode']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ned_tables[12223].colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty_counter = 0\n",
    "# res_tab       = {}\n",
    "# for name in large_sample_names:\n",
    "#     try:\n",
    "#         res_tab[name] = customNed.query_region(large_sample_coords, radius=3.0*u.arcsec)[0]\n",
    "#         res_tab[name].remove_columns(fields_to_remove)\n",
    "#     except:\n",
    "#         res_tab[name] = Table()\n",
    "#         empty_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "if order_ned_photometry_flag:\n",
    "    limit_set_ned = int(np.floor(np.shape(ned_names)[0]/4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (18023 of 18023) |##################| Elapsed Time: 0:34:16 Time:  0:34:16\n"
     ]
    }
   ],
   "source": [
    "if order_ned_photometry_flag:\n",
    "    temp_table_ned_photo             = Table()\n",
    "    chunk_size                       = 300  # Number of elements to calculate before dumping results to external table\n",
    "    with progressbar.ProgressBar(min_value=0, max_value=np.shape(ned_names)[0]) as bar:\n",
    "        for index, source_name in enumerate(ned_names):  # Some names will be. 'No Name'\n",
    "            band_names_str           = []\n",
    "            column_names_str         = []\n",
    "            band_frequencies         = []\n",
    "            measure_names            = ned_tables[index].colnames[1:]\n",
    "            # init_table = Table(names=('MAIN_ID',), dtype=('str',), masked=True)\n",
    "            cord_str                 = coords_simbad_inayoshi[index].to_string('decimal')\n",
    "            init_table               = Table(data=np.array([index, cord_str, source_name]), names=('INDEX', 'COORD', 'MAIN_ID'), dtype=('int', 'str', 'str'), masked=True)\n",
    "            if source_name == 'No Name':\n",
    "                # init_table = Table(('No Name',), names=('MAIN_ID',), dtype=('str',), masked=True)\n",
    "                # init_table.add_row(('No Name',), mask=(True,)) # Mask values in the last step instead\n",
    "                if index == 0 or (index % chunk_size == 1 and index > 1):\n",
    "                    init_table_large     = Table(init_table)\n",
    "                    bar.update(index)\n",
    "                    continue\n",
    "                init_table_large     = vstack([init_table_large, init_table])\n",
    "                if index % chunk_size == 0 and index > 0:\n",
    "                    temp_table_ned_photo = vstack([temp_table_ned_photo, init_table_large])\n",
    "                    # result_table_simbad_copy = join(result_table_simbad_copy, init_table_large, keys='COORD', join_type='outer')\n",
    "                bar.update(index)\n",
    "                continue\n",
    "            if len(measure_names) == 0:\n",
    "                # init_table = Table(('No Name',), names=('MAIN_ID',), dtype=('str',), masked=True)\n",
    "                # init_table.add_row((source_name,), mask=(True,))\n",
    "                if index == 0 or (index % chunk_size == 1 and index > 1):\n",
    "                    init_table_large     = Table(init_table)\n",
    "                    bar.update(index)\n",
    "                    continue\n",
    "                init_table_large     = vstack([init_table_large, init_table])\n",
    "                if index % chunk_size == 0 and index > 0:\n",
    "                    temp_table_ned_photo = vstack([temp_table_ned_photo, init_table_large])\n",
    "                    # result_table_simbad_copy = join(result_table_simbad_copy, init_table_large, keys='COORD', join_type='outer')\n",
    "                bar.update(index)\n",
    "                continue\n",
    "            # init_table = Table((str(source_name),), names=('MAIN_ID',), dtype=('str',), masked=True)\n",
    "            # init_table.add_row((str(source_name),))\n",
    "            for row in ned_tables[index]:\n",
    "                band_name_str        = re.sub(r' \\(.*', '', str(row['Observed Passband'].decode('utf-8')))  # Eliminate differences\n",
    "                if str(band_name_str) not in band_names_str and row['Frequency'] not in band_frequencies:\n",
    "                    band_frequencies.append(row['Frequency'])\n",
    "                    band_names_str.append(str(band_name_str))\n",
    "                    column_name_flux = 'Flux Density ' + band_name_str\n",
    "                    column_name_err  = 'NED Uncertainty ' + band_name_str\n",
    "                    if column_name_flux not in column_names_str:\n",
    "                        column_names_str.append(column_name_flux)\n",
    "                        column_flux  = MaskedColumn(row['Flux Density'], name=column_name_flux, unit=ned_tables[index]['Flux Density'].unit, dtype='float')\n",
    "                        column_err   = MaskedColumn(row['NED Uncertainty'], name=column_name_err, dtype='str')\n",
    "                        init_table.add_columns((column_flux, column_err))\n",
    "            #init_table.remove_column('MAIN_ID')\n",
    "            if index == 0 or (index % chunk_size == 1 and index > 1):\n",
    "                init_table_large     = Table(init_table)\n",
    "                bar.update(index)\n",
    "                continue\n",
    "            init_table_large         = vstack([init_table_large, init_table])\n",
    "            if index % chunk_size == 0 and index > 0:\n",
    "                temp_table_ned_photo = vstack([temp_table_ned_photo, init_table_large])\n",
    "                # result_table_simbad_copy = join(result_table_simbad_copy, init_table_large, keys='COORD', join_type='outer')\n",
    "            bar.update(index)\n",
    "    temp_table_ned_photo = vstack([temp_table_ned_photo, init_table_large])\n",
    "    # result_table_simbad_copy = join(result_table_simbad_copy, init_table_large, keys='COORD', join_type='outer')\n",
    "    #result_table_simbad_copy         = Table(result_table_simbad)\n",
    "    #result_table_simbad_copy.add_column(coords_simbad_inayoshi.to_string('decimal'), name='COORD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1055"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp_table_ned_photo.colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_simbad_inayoshi_ned_flag:\n",
    "    column_coord = MaskedColumn(temp_table_ned_photo['COORD'], name='COORD', mask=np.array(temp_table_ned_photo['COORD'] == ''))\n",
    "    column_id = MaskedColumn(temp_table_ned_photo['MAIN_ID'], name='MAIN_ID', description='Main identifier for an object', mask=np.array(temp_table_ned_photo['MAIN_ID'] == 'No Name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_simbad_inayoshi_ned_flag:\n",
    "    temp_table_ned_photo.replace_column('COORD', column_coord)\n",
    "    temp_table_ned_photo.replace_column('MAIN_ID', column_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_simbad_inayoshi_ned_flag:\n",
    "    df_ned    = temp_table_ned_photo.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_simbad_inayoshi_ned_flag:\n",
    "    df_simbad = result_table_simbad.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RA_d</th>\n",
       "      <th>DEC_d</th>\n",
       "      <th>Z_VALUE</th>\n",
       "      <th>FLUX_B</th>\n",
       "      <th>FLUX_ERROR_B</th>\n",
       "      <th>FLUX_V</th>\n",
       "      <th>FLUX_ERROR_V</th>\n",
       "      <th>FLUX_R</th>\n",
       "      <th>FLUX_ERROR_R</th>\n",
       "      <th>FLUX_I</th>\n",
       "      <th>...</th>\n",
       "      <th>Z_OWN_ERR</th>\n",
       "      <th>L_20CM</th>\n",
       "      <th>L_20CM_ERR</th>\n",
       "      <th>L_250GHZ</th>\n",
       "      <th>L_250GHZ_ERR</th>\n",
       "      <th>F_20CM</th>\n",
       "      <th>F_20CM_ERR</th>\n",
       "      <th>F_250GHZ</th>\n",
       "      <th>F_250GHZ_ERR</th>\n",
       "      <th>MASS_1450</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18023.000000</td>\n",
       "      <td>18023.000000</td>\n",
       "      <td>16379.000000</td>\n",
       "      <td>9062.000000</td>\n",
       "      <td>6795.000000</td>\n",
       "      <td>9166.000000</td>\n",
       "      <td>6834.000000</td>\n",
       "      <td>5540.000000</td>\n",
       "      <td>5241.000000</td>\n",
       "      <td>5856.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8650.000000</td>\n",
       "      <td>1.795700e+04</td>\n",
       "      <td>1.793800e+04</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>17957.000000</td>\n",
       "      <td>17938.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.700000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>165.161309</td>\n",
       "      <td>14.413467</td>\n",
       "      <td>1.686053</td>\n",
       "      <td>23.330841</td>\n",
       "      <td>0.078736</td>\n",
       "      <td>22.782164</td>\n",
       "      <td>0.068906</td>\n",
       "      <td>23.307508</td>\n",
       "      <td>0.060399</td>\n",
       "      <td>22.746859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006880</td>\n",
       "      <td>4.736101e+26</td>\n",
       "      <td>3.147703e+24</td>\n",
       "      <td>2.160516e+28</td>\n",
       "      <td>7.353389e+27</td>\n",
       "      <td>19.074815</td>\n",
       "      <td>0.125621</td>\n",
       "      <td>1.732615</td>\n",
       "      <td>0.590308</td>\n",
       "      <td>2.556118e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>48.779566</td>\n",
       "      <td>18.108288</td>\n",
       "      <td>0.946778</td>\n",
       "      <td>2.664027</td>\n",
       "      <td>0.092610</td>\n",
       "      <td>2.596944</td>\n",
       "      <td>0.090806</td>\n",
       "      <td>2.233830</td>\n",
       "      <td>0.090315</td>\n",
       "      <td>1.985852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.622824</td>\n",
       "      <td>2.727563e+27</td>\n",
       "      <td>1.109735e+25</td>\n",
       "      <td>3.129408e+28</td>\n",
       "      <td>3.806932e+27</td>\n",
       "      <td>158.854176</td>\n",
       "      <td>0.816971</td>\n",
       "      <td>2.599729</td>\n",
       "      <td>0.313668</td>\n",
       "      <td>2.737439e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.005324</td>\n",
       "      <td>-22.028390</td>\n",
       "      <td>-0.003370</td>\n",
       "      <td>14.910000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.040000</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>9.646523e+15</td>\n",
       "      <td>1.348291e+15</td>\n",
       "      <td>8.841515e+26</td>\n",
       "      <td>6.799705e+26</td>\n",
       "      <td>0.003896</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>6.550000e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>149.768810</td>\n",
       "      <td>2.099269</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>20.910000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>20.459999</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>21.969500</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>21.381500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>3.574307e+22</td>\n",
       "      <td>3.932484e+21</td>\n",
       "      <td>2.517779e+27</td>\n",
       "      <td>5.655792e+27</td>\n",
       "      <td>0.004959</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>1.230000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>150.405080</td>\n",
       "      <td>2.735560</td>\n",
       "      <td>1.567000</td>\n",
       "      <td>24.031000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>23.320000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>23.639999</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>22.809999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>8.950888e+23</td>\n",
       "      <td>7.585818e+22</td>\n",
       "      <td>9.812243e+27</td>\n",
       "      <td>7.359182e+27</td>\n",
       "      <td>0.212533</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.720000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>182.881579</td>\n",
       "      <td>25.482843</td>\n",
       "      <td>2.410000</td>\n",
       "      <td>25.480000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>24.870001</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>24.942001</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>24.230000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.421476e+26</td>\n",
       "      <td>4.594716e+24</td>\n",
       "      <td>2.251746e+28</td>\n",
       "      <td>1.048921e+28</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.152514</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.730000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>359.905497</td>\n",
       "      <td>64.522768</td>\n",
       "      <td>7.541300</td>\n",
       "      <td>28.837999</td>\n",
       "      <td>1.247000</td>\n",
       "      <td>27.990000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>27.959999</td>\n",
       "      <td>...</td>\n",
       "      <td>41.853600</td>\n",
       "      <td>1.894966e+29</td>\n",
       "      <td>4.082157e+26</td>\n",
       "      <td>1.140597e+29</td>\n",
       "      <td>1.369149e+28</td>\n",
       "      <td>14774.419900</td>\n",
       "      <td>71.099998</td>\n",
       "      <td>9.460000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>1.240000e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               RA_d         DEC_d       Z_VALUE       FLUX_B  FLUX_ERROR_B  \\\n",
       "count  18023.000000  18023.000000  16379.000000  9062.000000   6795.000000   \n",
       "mean     165.161309     14.413467      1.686053    23.330841      0.078736   \n",
       "std       48.779566     18.108288      0.946778     2.664027      0.092610   \n",
       "min        0.005324    -22.028390     -0.003370    14.910000      0.000000   \n",
       "25%      149.768810      2.099269      0.887850    20.910000      0.020000   \n",
       "50%      150.405080      2.735560      1.567000    24.031000      0.050000   \n",
       "75%      182.881579     25.482843      2.410000    25.480000      0.090000   \n",
       "max      359.905497     64.522768      7.541300    28.837999      1.247000   \n",
       "\n",
       "            FLUX_V  FLUX_ERROR_V       FLUX_R  FLUX_ERROR_R       FLUX_I  ...  \\\n",
       "count  9166.000000   6834.000000  5540.000000   5241.000000  5856.000000  ...   \n",
       "mean     22.782164      0.068906    23.307508      0.060399    22.746859  ...   \n",
       "std       2.596944      0.090806     2.233830      0.090315     1.985852  ...   \n",
       "min      14.800000      0.002000    13.800000      0.000000    15.040000  ...   \n",
       "25%      20.459999      0.020000    21.969500      0.010000    21.381500  ...   \n",
       "50%      23.320000      0.040000    23.639999      0.030000    22.809999  ...   \n",
       "75%      24.870001      0.080000    24.942001      0.060000    24.230000  ...   \n",
       "max      27.990000      0.970000    28.000000      0.810000    27.959999  ...   \n",
       "\n",
       "         Z_OWN_ERR        L_20CM    L_20CM_ERR      L_250GHZ  L_250GHZ_ERR  \\\n",
       "count  8650.000000  1.795700e+04  1.793800e+04  1.300000e+01  1.300000e+01   \n",
       "mean      0.006880  4.736101e+26  3.147703e+24  2.160516e+28  7.353389e+27   \n",
       "std       0.622824  2.727563e+27  1.109735e+25  3.129408e+28  3.806932e+27   \n",
       "min      -6.000000  9.646523e+15  1.348291e+15  8.841515e+26  6.799705e+26   \n",
       "25%       0.000200  3.574307e+22  3.932484e+21  2.517779e+27  5.655792e+27   \n",
       "50%       0.000400  8.950888e+23  7.585818e+22  9.812243e+27  7.359182e+27   \n",
       "75%       0.000600  1.421476e+26  4.594716e+24  2.251746e+28  1.048921e+28   \n",
       "max      41.853600  1.894966e+29  4.082157e+26  1.140597e+29  1.369149e+28   \n",
       "\n",
       "             F_20CM    F_20CM_ERR   F_250GHZ  F_250GHZ_ERR     MASS_1450  \n",
       "count  17957.000000  17938.000000  13.000000     13.000000  1.700000e+01  \n",
       "mean      19.074815      0.125621   1.732615      0.590308  2.556118e+09  \n",
       "std      158.854176      0.816971   2.599729      0.313668  2.737439e+09  \n",
       "min        0.003896      0.000372   0.070000      0.040000  6.550000e+08  \n",
       "25%        0.004959      0.000609   0.210000      0.460000  1.230000e+09  \n",
       "50%        0.212533      0.017000   0.800000      0.600000  1.720000e+09  \n",
       "75%        5.500000      0.152514   1.820000      0.800000  2.730000e+09  \n",
       "max    14774.419900     71.099998   9.460000      1.130000  1.240000e+10  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_simbad_inayoshi_ned_flag:\n",
    "    merged_ned_simbad = pd.merge(df_simbad, df_ned, on='INDEX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MAIN_ID_x', 'RA_d', 'DEC_d', 'Z_VALUE', 'FLUX_B', 'FLUX_ERROR_B',\n",
       "       'FLUX_V', 'FLUX_ERROR_V', 'FLUX_R', 'FLUX_ERROR_R', 'FLUX_I',\n",
       "       'FLUX_ERROR_I', 'FLUX_J', 'FLUX_ERROR_J', 'FLUX_K', 'FLUX_ERROR_K',\n",
       "       'INDEX', 'CAT_NAME', 'COORD_x', 'Z_OWN', 'Z_OWN_ERR', 'L_20CM',\n",
       "       'L_20CM_ERR', 'L_20CM_UP_LIM', 'L_250GHZ', 'L_250GHZ_ERR', 'F_20CM',\n",
       "       'F_20CM_ERR', 'F_250GHZ', 'F_250GHZ_ERR', 'MASS_1450', 'COORD_y',\n",
       "       'MAIN_ID_y', 'Flux Density u', 'NED Uncertainty u', 'Flux Density g',\n",
       "       'NED Uncertainty g', 'Flux Density r', 'NED Uncertainty r',\n",
       "       'Flux Density i'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merged_ned_simbad.columns[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COORD_x</th>\n",
       "      <th>COORD_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18000</th>\n",
       "      <td>149.539 2.93855</td>\n",
       "      <td>149.539 2.93855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18001</th>\n",
       "      <td>149.745 2.93884</td>\n",
       "      <td>149.745 2.93884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18002</th>\n",
       "      <td>150.489 2.93917</td>\n",
       "      <td>150.489 2.93917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18003</th>\n",
       "      <td>150.006 2.93915</td>\n",
       "      <td>150.006 2.93915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18004</th>\n",
       "      <td>150.809 2.93986</td>\n",
       "      <td>150.809 2.93986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18005</th>\n",
       "      <td>150.398 2.94012</td>\n",
       "      <td>150.398 2.94012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18006</th>\n",
       "      <td>150.085 2.94013</td>\n",
       "      <td>150.085 2.94013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18007</th>\n",
       "      <td>149.538 2.94105</td>\n",
       "      <td>149.538 2.94105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18008</th>\n",
       "      <td>150.56 2.94199</td>\n",
       "      <td>150.56 2.94199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18009</th>\n",
       "      <td>149.698 2.94245</td>\n",
       "      <td>149.698 2.94245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18010</th>\n",
       "      <td>150.451 2.94251</td>\n",
       "      <td>150.451 2.94251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               COORD_x          COORD_y\n",
       "18000  149.539 2.93855  149.539 2.93855\n",
       "18001  149.745 2.93884  149.745 2.93884\n",
       "18002  150.489 2.93917  150.489 2.93917\n",
       "18003  150.006 2.93915  150.006 2.93915\n",
       "18004  150.809 2.93986  150.809 2.93986\n",
       "18005  150.398 2.94012  150.398 2.94012\n",
       "18006  150.085 2.94013  150.085 2.94013\n",
       "18007  149.538 2.94105  149.538 2.94105\n",
       "18008   150.56 2.94199   150.56 2.94199\n",
       "18009  149.698 2.94245  149.698 2.94245\n",
       "18010  150.451 2.94251  150.451 2.94251"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merged_ned_simbad.loc[18000:18010, ['COORD_x', 'COORD_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RA_d</th>\n",
       "      <th>DEC_d</th>\n",
       "      <th>Z_VALUE</th>\n",
       "      <th>FLUX_B</th>\n",
       "      <th>FLUX_ERROR_B</th>\n",
       "      <th>FLUX_V</th>\n",
       "      <th>FLUX_ERROR_V</th>\n",
       "      <th>FLUX_R</th>\n",
       "      <th>FLUX_ERROR_R</th>\n",
       "      <th>FLUX_I</th>\n",
       "      <th>...</th>\n",
       "      <th>Flux Density 203.850 GHz</th>\n",
       "      <th>Flux Density 163.088 GHz</th>\n",
       "      <th>Flux Density 81.551 GHz</th>\n",
       "      <th>Flux Density [OII] 3727</th>\n",
       "      <th>Flux Density [NeIII] 3869 VIRUS-P</th>\n",
       "      <th>Flux Density [OIII] 5007 VIRUS-P</th>\n",
       "      <th>Flux Density 890 microns</th>\n",
       "      <th>Flux Density 1.1 mm</th>\n",
       "      <th>Flux Density 345 GHz</th>\n",
       "      <th>Flux Density 830 A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18023.000000</td>\n",
       "      <td>18023.000000</td>\n",
       "      <td>16379.000000</td>\n",
       "      <td>9062.000000</td>\n",
       "      <td>6795.000000</td>\n",
       "      <td>9166.000000</td>\n",
       "      <td>6834.000000</td>\n",
       "      <td>5540.000000</td>\n",
       "      <td>5241.000000</td>\n",
       "      <td>5856.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>165.161309</td>\n",
       "      <td>14.413467</td>\n",
       "      <td>1.686053</td>\n",
       "      <td>23.330841</td>\n",
       "      <td>0.078736</td>\n",
       "      <td>22.782164</td>\n",
       "      <td>0.068906</td>\n",
       "      <td>23.307508</td>\n",
       "      <td>0.060399</td>\n",
       "      <td>22.746859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.00839</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>6.729167e+07</td>\n",
       "      <td>95000000.0</td>\n",
       "      <td>71000000.0</td>\n",
       "      <td>0.012162</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.021</td>\n",
       "      <td>1.520000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>48.779566</td>\n",
       "      <td>18.108288</td>\n",
       "      <td>0.946778</td>\n",
       "      <td>2.664027</td>\n",
       "      <td>0.092610</td>\n",
       "      <td>2.596944</td>\n",
       "      <td>0.090806</td>\n",
       "      <td>2.233830</td>\n",
       "      <td>0.090315</td>\n",
       "      <td>1.985852</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.331242e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004622</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.949747e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.005324</td>\n",
       "      <td>-22.028390</td>\n",
       "      <td>-0.003370</td>\n",
       "      <td>14.910000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.040000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.00839</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>1.030000e+07</td>\n",
       "      <td>95000000.0</td>\n",
       "      <td>71000000.0</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.021</td>\n",
       "      <td>1.170000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>149.768810</td>\n",
       "      <td>2.099269</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>20.910000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>20.459999</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>21.969500</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>21.381500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.00839</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>2.092500e+07</td>\n",
       "      <td>95000000.0</td>\n",
       "      <td>71000000.0</td>\n",
       "      <td>0.009125</td>\n",
       "      <td>0.004250</td>\n",
       "      <td>0.021</td>\n",
       "      <td>1.345000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>150.405080</td>\n",
       "      <td>2.735560</td>\n",
       "      <td>1.567000</td>\n",
       "      <td>24.031000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>23.320000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>23.639999</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>22.809999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.00839</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>3.685000e+07</td>\n",
       "      <td>95000000.0</td>\n",
       "      <td>71000000.0</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.021</td>\n",
       "      <td>1.520000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>182.881579</td>\n",
       "      <td>25.482843</td>\n",
       "      <td>2.410000</td>\n",
       "      <td>25.480000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>24.870001</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>24.942001</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>24.230000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.00839</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>6.282500e+07</td>\n",
       "      <td>95000000.0</td>\n",
       "      <td>71000000.0</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.006350</td>\n",
       "      <td>0.021</td>\n",
       "      <td>1.695000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>359.905497</td>\n",
       "      <td>64.522768</td>\n",
       "      <td>7.541300</td>\n",
       "      <td>28.837999</td>\n",
       "      <td>1.247000</td>\n",
       "      <td>27.990000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>27.959999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.00839</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>2.850000e+08</td>\n",
       "      <td>95000000.0</td>\n",
       "      <td>71000000.0</td>\n",
       "      <td>0.021600</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.021</td>\n",
       "      <td>1.870000e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 553 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               RA_d         DEC_d       Z_VALUE       FLUX_B  FLUX_ERROR_B  \\\n",
       "count  18023.000000  18023.000000  16379.000000  9062.000000   6795.000000   \n",
       "mean     165.161309     14.413467      1.686053    23.330841      0.078736   \n",
       "std       48.779566     18.108288      0.946778     2.664027      0.092610   \n",
       "min        0.005324    -22.028390     -0.003370    14.910000      0.000000   \n",
       "25%      149.768810      2.099269      0.887850    20.910000      0.020000   \n",
       "50%      150.405080      2.735560      1.567000    24.031000      0.050000   \n",
       "75%      182.881579     25.482843      2.410000    25.480000      0.090000   \n",
       "max      359.905497     64.522768      7.541300    28.837999      1.247000   \n",
       "\n",
       "            FLUX_V  FLUX_ERROR_V       FLUX_R  FLUX_ERROR_R       FLUX_I  ...  \\\n",
       "count  9166.000000   6834.000000  5540.000000   5241.000000  5856.000000  ...   \n",
       "mean     22.782164      0.068906    23.307508      0.060399    22.746859  ...   \n",
       "std       2.596944      0.090806     2.233830      0.090315     1.985852  ...   \n",
       "min      14.800000      0.002000    13.800000      0.000000    15.040000  ...   \n",
       "25%      20.459999      0.020000    21.969500      0.010000    21.381500  ...   \n",
       "50%      23.320000      0.040000    23.639999      0.030000    22.809999  ...   \n",
       "75%      24.870001      0.080000    24.942001      0.060000    24.230000  ...   \n",
       "max      27.990000      0.970000    28.000000      0.810000    27.959999  ...   \n",
       "\n",
       "       Flux Density 203.850 GHz  Flux Density 163.088 GHz  \\\n",
       "count                    1.0000                   1.00000   \n",
       "mean                     0.0116                   0.00839   \n",
       "std                         NaN                       NaN   \n",
       "min                      0.0116                   0.00839   \n",
       "25%                      0.0116                   0.00839   \n",
       "50%                      0.0116                   0.00839   \n",
       "75%                      0.0116                   0.00839   \n",
       "max                      0.0116                   0.00839   \n",
       "\n",
       "       Flux Density 81.551 GHz  Flux Density [OII] 3727  \\\n",
       "count                  1.00000             1.200000e+01   \n",
       "mean                   0.00308             6.729167e+07   \n",
       "std                        NaN             8.331242e+07   \n",
       "min                    0.00308             1.030000e+07   \n",
       "25%                    0.00308             2.092500e+07   \n",
       "50%                    0.00308             3.685000e+07   \n",
       "75%                    0.00308             6.282500e+07   \n",
       "max                    0.00308             2.850000e+08   \n",
       "\n",
       "       Flux Density [NeIII] 3869 VIRUS-P  Flux Density [OIII] 5007 VIRUS-P  \\\n",
       "count                                1.0                               1.0   \n",
       "mean                          95000000.0                        71000000.0   \n",
       "std                                  NaN                               NaN   \n",
       "min                           95000000.0                        71000000.0   \n",
       "25%                           95000000.0                        71000000.0   \n",
       "50%                           95000000.0                        71000000.0   \n",
       "75%                           95000000.0                        71000000.0   \n",
       "max                           95000000.0                        71000000.0   \n",
       "\n",
       "       Flux Density 890 microns  Flux Density 1.1 mm  Flux Density 345 GHz  \\\n",
       "count                  8.000000            16.000000                 1.000   \n",
       "mean                   0.012162             0.005337                 0.021   \n",
       "std                    0.004622             0.002011                   NaN   \n",
       "min                    0.007400             0.002600                 0.021   \n",
       "25%                    0.009125             0.004250                 0.021   \n",
       "50%                    0.011000             0.005300                 0.021   \n",
       "75%                    0.013500             0.006350                 0.021   \n",
       "max                    0.021600             0.009300                 0.021   \n",
       "\n",
       "       Flux Density 830 A  \n",
       "count        2.000000e+00  \n",
       "mean         1.520000e-08  \n",
       "std          4.949747e-09  \n",
       "min          1.170000e-08  \n",
       "25%          1.345000e-08  \n",
       "50%          1.520000e-08  \n",
       "75%          1.695000e-08  \n",
       "max          1.870000e-08  \n",
       "\n",
       "[8 rows x 553 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merged_ned_simbad.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rcarvajalp/.anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:2505: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block4_values] [items->Index(['MAIN_ID_x', 'CAT_NAME', 'COORD_x', 'COORD_y', 'MAIN_ID_y',\n",
      "       'NED Uncertainty u', 'NED Uncertainty g', 'NED Uncertainty r',\n",
      "       'NED Uncertainty i', 'NED Uncertainty z',\n",
      "       ...\n",
      "       'NED Uncertainty 203.850 GHz', 'NED Uncertainty 163.088 GHz',\n",
      "       'NED Uncertainty 81.551 GHz', 'NED Uncertainty [OII] 3727',\n",
      "       'NED Uncertainty [NeIII] 3869 VIRUS-P',\n",
      "       'NED Uncertainty [OIII] 5007 VIRUS-P', 'NED Uncertainty 890 microns',\n",
      "       'NED Uncertainty 1.1 mm', 'NED Uncertainty 345 GHz',\n",
      "       'NED Uncertainty 830 A'],\n",
      "      dtype='object', length=531)]\n",
      "\n",
      "  encoding=encoding,\n"
     ]
    }
   ],
   "source": [
    "if create_simbad_inayoshi_ned_flag:\n",
    "    merged_ned_simbad.to_hdf('large_cat_simbad_inayoshi_ned.h5', 'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "if read_simbad_inayoshi_ned_flag:\n",
    "    power_test = pd.read_hdf('large_cat_simbad_inayoshi_ned.h5', 'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# power_table = Table.from_pandas(power_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18023"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(np.unique(np.arange(18023)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_table_copy['1.4_GHz_(VLA)_Flux_Density', '1.4GHz_Flux_Density'].info(['attributes', 'stats'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name in large_sample_names:\n",
    "#     print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDs to be changed for use in NED\n",
    "\n",
    "OLD                          NEW\n",
    "\n",
    "SDSS J125507.61+463126.5     NVSS J125507+463128  \n",
    "SDSS J160558.86+474300.1     2MASS J16055893+4742596  \n",
    "SDSS J111036.32+481752.3     NVSS J111036+481753  \n",
    "SDSS J163033.89+401209.6     SDSS J163033.90+401209.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import OPTICS\n",
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KMeans(n_clusters=6)  # Best suited for straight boundaries\n",
    "estimator.fit(data_z_L14[[0, 2], :].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_test = SpectralClustering(n_clusters=5, affinity='nearest_neighbors', assign_labels='kmeans')\n",
    "model_test = OPTICS(min_samples=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpectralClustering(n_clusters=2, affinity='nearest_neighbors', assign_labels='kmeans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_km = estimator.labels_\n",
    "labels_sc = model.fit_predict(data_z_L14[[0, 2], :].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(~np.isfinite(data_z_L14[2, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = model_test.fit_predict(data_z_L14[[0, 2], :].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(data_z_L14[[0, 2], :].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_z_L14[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,5))\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "\n",
    "ax1.scatter(data_z_L14[0, :], data_z_L14[2, :], c=labels_km, edgecolor='k', s=50, cmap='inferno')\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_ylim((1e23, 1e29))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,5))\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "\n",
    "ax1.scatter(data_z_L14[0, :], data_z_L14[2, :], c='k', edgecolor='k', s=50, cmap='inferno')\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_ylim((1e23, 1e29))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,5))\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "\n",
    "ax1.scatter(large_sample_z, large_sample_L, c=labels_test, edgecolor='k', s=50, cmap='inferno')\n",
    "ax1.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
